{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "demanding-saskatchewan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, log_loss, classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, CategoricalNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import Pool, CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prompt-beginning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# датасет Доминики\n",
    "df = pd.read_csv('bib_data_union_v4.csv.zip', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "therapeutic-intelligence",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = small_dataset.tokenized_record\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "vect_df = pd.DataFrame(vectorizer.fit_transform(corpus).toarray())\n",
    "# vect_df['style_name'] = small_dataset['style_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b67318d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {}\n",
    "for i, st in enumerate(set(small_dataset.style_name)):\n",
    "    vocabulary[st] = i\n",
    "\n",
    "y = pd.Series([vocabulary[st] for st in list(small_dataset.style_name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6cb0f003",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_df['style_name'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5fba88ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "      <th>384</th>\n",
       "      <th>385</th>\n",
       "      <th>style_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 387 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  ...  377  378  379  380  381  382  383  384  \\\n",
       "0  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    1    0    0    0    0   \n",
       "1  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    1   \n",
       "2  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    1   \n",
       "3  0  0  0  0  0  0  0  0  0  0  ...    0    0    1    1    0    0    0    0   \n",
       "4  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "\n",
       "   385  style_name  \n",
       "0    0          74  \n",
       "1    0          81  \n",
       "2    0          77  \n",
       "3    0          52  \n",
       "4    0           3  \n",
       "\n",
       "[5 rows x 387 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "going-practitioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_dataset, small_dataset = train_test_split(df, test_size=0.017, random_state=110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "usual-pittsburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "NGRAM_RANGE = (2, 4)\n",
    "\n",
    "def select_features_rf(tfidf, response, feature_names, nfeatures):\n",
    "    '''Select features using feature importance from Random Forest'''\n",
    "\n",
    "    if nfeatures >= len(feature_names):\n",
    "        return feature_names\n",
    "    rf = RandomForestClassifier(n_estimators=200, max_depth=3, random_state=5)\n",
    "    rf_model = rf.fit(tfidf, response)\n",
    "    feature_importances = np.argsort(rf_model.feature_importances_)\n",
    "    feature_names = np.array(feature_names)\n",
    "    feature_names = feature_names[feature_importances]\n",
    "    return feature_names[-nfeatures:]\n",
    "\n",
    "\n",
    "def select_features_chi2(tfidf, response, feature_names, nfeatures):\n",
    "    '''Select features using Chi-squared correlations'''\n",
    "\n",
    "    if nfeatures >= len(feature_names):\n",
    "        return feature_names\n",
    "    feature_names_sorted = []\n",
    "    for label in list(set(response)):\n",
    "        features_chi2 = chi2(tfidf, response == label)[0]\n",
    "        indices = np.argsort(features_chi2)\n",
    "        fns = np.array(feature_names)\n",
    "        fns = fns[indices][::-1]\n",
    "        feature_names_sorted.append(fns)\n",
    "    feature_names = set()\n",
    "    for i in range(nfeatures):\n",
    "        if len(feature_names) == nfeatures:\n",
    "            break\n",
    "        nf = [x[i] for x in feature_names_sorted]\n",
    "        for n in nf:\n",
    "            if len(feature_names) == nfeatures:\n",
    "                break\n",
    "            feature_names.add(n)\n",
    "    return feature_names\n",
    "\n",
    "\n",
    "def get_tfidf_features(strings,\n",
    "                       response=None,\n",
    "                       count_vectorizer=None,\n",
    "                       tfidf_transformer=None,\n",
    "                       nfeatures=None,\n",
    "                       ngrams=NGRAM_RANGE,\n",
    "                       feature_selector=None):\n",
    "    '''Extract TF-IDF from reference strings'''\n",
    "\n",
    "    if count_vectorizer is None:\n",
    "        # fit and calculate features (train set mode)\n",
    "        freq_nfeatures = None\n",
    "        if feature_selector is None:\n",
    "            freq_nfeatures = nfeatures\n",
    "        count_vectorizer = CountVectorizer(preprocessor=tokens_to_classes,\n",
    "                                           max_features=freq_nfeatures,\n",
    "                                           ngram_range=ngrams)\n",
    "        counts = count_vectorizer.fit_transform(strings)\n",
    "        tfidf_transformer = TfidfTransformer()\n",
    "        tfidf = tfidf_transformer.fit_transform(counts)\n",
    "        if feature_selector is not None and nfeatures is not None \\\n",
    "                and response is not None:\n",
    "            # feature selection\n",
    "            feature_names = count_vectorizer.get_feature_names()\n",
    "            if nfeatures < len(feature_names):\n",
    "                feature_names = feature_selector(tfidf, response,\n",
    "                                                 feature_names, nfeatures)\n",
    "            count_vectorizer = CountVectorizer(preprocessor=tokens_to_classes,\n",
    "                                               ngram_range=ngrams,\n",
    "                                               vocabulary=feature_names)\n",
    "            counts = count_vectorizer.fit_transform(strings)\n",
    "            tfidf_transformer = TfidfTransformer()\n",
    "            tfidf = tfidf_transformer.fit_transform(counts)\n",
    "    else:\n",
    "        # calculate features (test set mode)\n",
    "        counts = count_vectorizer.transform(strings)\n",
    "        tfidf = tfidf_transformer.transform(counts)\n",
    "    return count_vectorizer, tfidf_transformer, tfidf\n",
    "\n",
    "\n",
    "def get_features(strings,\n",
    "                 response=None,\n",
    "                 count_vectorizer=None,\n",
    "                 tfidf_transformer=None,\n",
    "                 nfeatures=None,\n",
    "                 ngrams=NGRAM_RANGE,\n",
    "                 feature_selector=None):\n",
    "    '''Extract full feature vector from reference strings'''\n",
    "\n",
    "    count_vectorizer, tfidf_transformer, features = \\\n",
    "        get_tfidf_features(strings, response=response, nfeatures=nfeatures,\n",
    "                           count_vectorizer=count_vectorizer,\n",
    "                           tfidf_transformer=tfidf_transformer,\n",
    "                           ngrams=ngrams, feature_selector=feature_selector)\n",
    "    lengths = [[len(s)] for s in strings]\n",
    "    features = sp.hstack((features, sp.csr_matrix(lengths)))\n",
    "\n",
    "    return count_vectorizer, tfidf_transformer, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b3d9114",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_df = vect_df.reset_index()\n",
    "vect_df.columns = vect_df.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1c98a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_df = vect_df.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6eca0bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "      <th>384</th>\n",
       "      <th>385</th>\n",
       "      <th>style_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 387 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  ...  377  378  379  380  381  382  383  384  \\\n",
       "0  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    1    0    0    0    0   \n",
       "1  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    1   \n",
       "2  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    1   \n",
       "3  0  0  0  0  0  0  0  0  0  0  ...    0    0    1    1    0    0    0    0   \n",
       "4  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "\n",
       "   385  style_name  \n",
       "0    0          74  \n",
       "1    0          81  \n",
       "2    0          77  \n",
       "3    0          52  \n",
       "4    0           3  \n",
       "\n",
       "[5 rows x 387 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "shared-yeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_X,small_y = vect_df.drop(['style_name'], axis=1), vect_df.style_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "miniature-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_X_train, small_X_test, small_y_train, small_y_test = train_test_split(small_X, small_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476cc265",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_X, big_y = big_dataset.drop(['style_name'], axis=1), big_dataset.style_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "certain-handle",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alrabosh/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/home/alrabosh/miniconda3/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7131107412121805\n",
      "Time =  1798.1568381786346 s = 30 min\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from math import ceil\n",
    "\n",
    "sgd_model = LogisticRegression(solver='liblinear', multi_class='ovr',\n",
    "            random_state=0, n_jobs=8)\n",
    "start = time.time()\n",
    "sgd_model.fit(small_X_train, small_y_train)\n",
    "finish = time.time()\n",
    "print(sgd_model.score(small_X_test, small_y_test))\n",
    "print(\"Time = \", finish - start, \"s =\", ceil((finish - start) / 60), \"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b3b8601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(np.isnan(small_X.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e50f9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score(small_y_test, sgd_model.predict(small_X_test), average='macro'))\n",
    "print(f1_score(big_y, sgd_model.predict(big_X), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10039a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "guided-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('2grams_bib_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "simplified-florida",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df, small_df = train_test_split(df, test_size=0.017, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "conscious-count",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_X, small_y = small_df.drop(['style_name'], axis=1), small_df.style_name\n",
    "big_X, big_y = big_df.drop(['style_name'], axis=1), big_df.style_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00ab8b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df.to_csv('small_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8689c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_X_train, small_X_test, small_y_train, small_y_test = train_test_split(small_X, small_y, test_size=0.2)\n",
    "small_X_train, small_X_val, small_y_train, small_y_val = train_test_split(small_X_train, small_y_train, test_size=0.25)\n",
    "train_dataset = Pool(data=small_X_train, label=small_y_train)\n",
    "test_data = Pool(data=small_X_test, label=small_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-cancer",
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_model = CatBoostClassifier(iterations=250,\n",
    "                           learning_rate=0.05,\n",
    "                           depth=4,\n",
    "                           task_type='GPU',                                                \n",
    "                           loss_function='MultiClass',\n",
    "                           eval_metric='Accuracy')\n",
    "boost_model.fit(train_dataset, eval_set=(small_X_val, small_y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30a19f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f29fc6079d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_model = CatBoostClassifier()\n",
    "boost_model.load_model('boost_model(2).cbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "greatest-webster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7059910484211966\n",
      "0.7059910484211966\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(big_y, boost_model.predict(big_X)))\n",
    "print(f1_score(big_y, boost_model.predict(big_X), average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec098fd",
   "metadata": {},
   "source": [
    "# Нейронная сеть sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d1a3b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f141a9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), max_iter=10000,\n",
       "              random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), max_iter=10000,\n",
       "              random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), max_iter=10000,\n",
       "              random_state=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='adam', alpha=1e-5,\n",
    "                     hidden_layer_sizes=(5, 2), random_state=1, max_iter=10000, activation='relu')\n",
    "clf.fit(small_X_train, small_y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
