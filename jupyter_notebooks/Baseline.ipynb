{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "demanding-saskatchewan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, log_loss, classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, CategoricalNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import Pool, CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prompt-beginning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# датасет Доминики\n",
    "df = pd.read_csv('bib_data_union_v4.csv.zip', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3b4d2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# наш датасет\n",
    "df = pd.read_csv('bib_data_union_v3.csv.zip', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "therapeutic-intelligence",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alrabosh/miniconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = small_dataset\n",
    "\n",
    "corpus = df.tokenized_record\n",
    "vectorizer = CountVectorizer(tokenizer=lambda txt: txt.split(), ngram_range=(1, 2))\n",
    "vect_df = pd.DataFrame(vectorizer.fit_transform(corpus).toarray())\n",
    "vect_df['style_name'] = df['style_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cb0f003",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_df.to_csv('2grams_bib_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1811ac13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "      <th>384</th>\n",
       "      <th>style_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 386 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  ...  376  377  378  379  380  381  382  383  \\\n",
       "0  2  0  0  0  0  0  0  0  0  1  ...    0    0    0    1    0    0    0    0   \n",
       "1  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "2  2  0  0  0  0  0  0  0  0  1  ...    0    0    0    0    0    0    0    0   \n",
       "3  1  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    1   \n",
       "4  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    1   \n",
       "\n",
       "   384  style_name  \n",
       "0    0         NaN  \n",
       "1    0         NaN  \n",
       "2    0         NaN  \n",
       "3    0         NaN  \n",
       "4    0         NaN  \n",
       "\n",
       "[5 rows x 386 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "going-practitioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_dataset, small_dataset = train_test_split(df, test_size=0.017, random_state=201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32f30fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dataset.to_csv('small_vect_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "usual-pittsburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "NGRAM_RANGE = (2, 4)\n",
    "\n",
    "def select_features_rf(tfidf, response, feature_names, nfeatures):\n",
    "    '''Select features using feature importance from Random Forest'''\n",
    "\n",
    "    if nfeatures >= len(feature_names):\n",
    "        return feature_names\n",
    "    rf = RandomForestClassifier(n_estimators=200, max_depth=3, random_state=5)\n",
    "    rf_model = rf.fit(tfidf, response)\n",
    "    feature_importances = np.argsort(rf_model.feature_importances_)\n",
    "    feature_names = np.array(feature_names)\n",
    "    feature_names = feature_names[feature_importances]\n",
    "    return feature_names[-nfeatures:]\n",
    "\n",
    "\n",
    "def select_features_chi2(tfidf, response, feature_names, nfeatures):\n",
    "    '''Select features using Chi-squared correlations'''\n",
    "\n",
    "    if nfeatures >= len(feature_names):\n",
    "        return feature_names\n",
    "    feature_names_sorted = []\n",
    "    for label in list(set(response)):\n",
    "        features_chi2 = chi2(tfidf, response == label)[0]\n",
    "        indices = np.argsort(features_chi2)\n",
    "        fns = np.array(feature_names)\n",
    "        fns = fns[indices][::-1]\n",
    "        feature_names_sorted.append(fns)\n",
    "    feature_names = set()\n",
    "    for i in range(nfeatures):\n",
    "        if len(feature_names) == nfeatures:\n",
    "            break\n",
    "        nf = [x[i] for x in feature_names_sorted]\n",
    "        for n in nf:\n",
    "            if len(feature_names) == nfeatures:\n",
    "                break\n",
    "            feature_names.add(n)\n",
    "    return feature_names\n",
    "\n",
    "\n",
    "def get_tfidf_features(strings,\n",
    "                       response=None,\n",
    "                       count_vectorizer=None,\n",
    "                       tfidf_transformer=None,\n",
    "                       nfeatures=None,\n",
    "                       ngrams=NGRAM_RANGE,\n",
    "                       feature_selector=None):\n",
    "    '''Extract TF-IDF from reference strings'''\n",
    "\n",
    "    if count_vectorizer is None:\n",
    "        # fit and calculate features (train set mode)\n",
    "        freq_nfeatures = None\n",
    "        if feature_selector is None:\n",
    "            freq_nfeatures = nfeatures\n",
    "        count_vectorizer = CountVectorizer(preprocessor=tokens_to_classes,\n",
    "                                           max_features=freq_nfeatures,\n",
    "                                           ngram_range=ngrams)\n",
    "        counts = count_vectorizer.fit_transform(strings)\n",
    "        tfidf_transformer = TfidfTransformer()\n",
    "        tfidf = tfidf_transformer.fit_transform(counts)\n",
    "        if feature_selector is not None and nfeatures is not None \\\n",
    "                and response is not None:\n",
    "            # feature selection\n",
    "            feature_names = count_vectorizer.get_feature_names()\n",
    "            if nfeatures < len(feature_names):\n",
    "                feature_names = feature_selector(tfidf, response,\n",
    "                                                 feature_names, nfeatures)\n",
    "            count_vectorizer = CountVectorizer(preprocessor=tokens_to_classes,\n",
    "                                               ngram_range=ngrams,\n",
    "                                               vocabulary=feature_names)\n",
    "            counts = count_vectorizer.fit_transform(strings)\n",
    "            tfidf_transformer = TfidfTransformer()\n",
    "            tfidf = tfidf_transformer.fit_transform(counts)\n",
    "    else:\n",
    "        # calculate features (test set mode)\n",
    "        counts = count_vectorizer.transform(strings)\n",
    "        tfidf = tfidf_transformer.transform(counts)\n",
    "    return count_vectorizer, tfidf_transformer, tfidf\n",
    "\n",
    "\n",
    "def get_features(strings,\n",
    "                 response=None,\n",
    "                 count_vectorizer=None,\n",
    "                 tfidf_transformer=None,\n",
    "                 nfeatures=None,\n",
    "                 ngrams=NGRAM_RANGE,\n",
    "                 feature_selector=None):\n",
    "    '''Extract full feature vector from reference strings'''\n",
    "\n",
    "    count_vectorizer, tfidf_transformer, features = \\\n",
    "        get_tfidf_features(strings, response=response, nfeatures=nfeatures,\n",
    "                           count_vectorizer=count_vectorizer,\n",
    "                           tfidf_transformer=tfidf_transformer,\n",
    "                           ngrams=ngrams, feature_selector=feature_selector)\n",
    "    lengths = [[len(s)] for s in strings]\n",
    "    features = sp.hstack((features, sp.csr_matrix(lengths)))\n",
    "\n",
    "    return count_vectorizer, tfidf_transformer, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "shared-yeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dataset = vect_df\n",
    "small_X,small_y = small_dataset.drop(['style_name'], axis=1), small_dataset.style_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "miniature-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_X_train, small_X_test, small_y_train, small_y_test = train_test_split(small_X, small_y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "476cc265",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_X, big_y = big_dataset.drop(['style_name'], axis=1), big_dataset.style_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "certain-handle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      5\u001b[0m sgd_model \u001b[38;5;241m=\u001b[39m LogisticRegression(solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m, multi_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m             random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43msgd_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msmall_X_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmall_y_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m finish \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# joblib.dump(sgd_model, 'dominika_model_our_ds.sav')\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1194\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m-> 1196\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1204\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 565\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:1122\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[1;32m   1106\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1107\u001b[0m     X,\n\u001b[1;32m   1108\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1119\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1120\u001b[0m )\n\u001b[0;32m-> 1122\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1124\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:1144\u001b[0m, in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1142\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1143\u001b[0m     y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 1144\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1145\u001b[0m     _ensure_no_complex_data(y)\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_numeric \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:111\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _object_dtype_isnan(X)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput contains NaN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# We need only consider float arrays, hence can early return for all else.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from math import ceil\n",
    "\n",
    "start = time.time()\n",
    "sgd_model = LogisticRegression(solver='liblinear', multi_class='ovr',\n",
    "            random_state=0, n_jobs=8)\n",
    "sgd_model.fit(small_X_train, small_y_train)\n",
    "finish = time.time()\n",
    "# joblib.dump(sgd_model, 'dominika_model_our_ds.sav')\n",
    "print(sgd_model.score(small_X_test, small_y_test))\n",
    "# print(sgd_model.score(big_X, big_y))\n",
    "print(finish - start, \"s = \", ceil((finish - start) / 60) + \"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e50f9cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alrabosh/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/alrabosh/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   IEEEannot       0.00      0.00      0.00       382\n",
      "    IEEEtran       0.02      0.42      0.04       387\n",
      "   IEEEtranN       0.02      0.00      0.00       370\n",
      "   IEEEtranS       0.00      0.00      0.00       349\n",
      "  IEEEtranSA       0.00      0.00      0.00       381\n",
      "  IEEEtranSN       0.01      0.10      0.02       399\n",
      "      JHEP-2       0.00      0.00      0.00       362\n",
      "  aaai-named       0.00      0.00      0.00       340\n",
      "    abstract       0.00      0.00      0.00       368\n",
      "    acmtrans       0.00      0.00      0.00       331\n",
      "      aichej       0.00      0.00      0.00       327\n",
      "         aip       0.00      0.00      0.00       368\n",
      "    alphanum       0.00      0.00      0.00       397\n",
      "         ama       0.00      0.00      0.00       329\n",
      "    amsalpha       0.00      0.00      0.00       262\n",
      "    amsplain       0.00      0.00      0.00       270\n",
      "    annotate       0.00      0.00      0.00       357\n",
      "  annotation       0.00      0.00      0.00       334\n",
      "         apa       0.00      0.00      0.00       337\n",
      "apalike-ejor       0.00      0.00      0.00       328\n",
      "     apasoft       0.00      0.00      0.00       377\n",
      "      astron       0.00      0.00      0.00       370\n",
      "         bbs       0.00      0.00      0.00       361\n",
      " besjournals       0.00      0.00      0.00       380\n",
      "  bestpapers       0.00      0.00      0.00         7\n",
      "     biolett       0.00      0.00      0.00       351\n",
      "      bookdb       0.00      0.00      0.00       306\n",
      "         cbe       0.00      0.00      0.00       376\n",
      "     chicago       0.00      0.00      0.00       363\n",
      "    chicagoa       0.00      0.00      0.00       365\n",
      "          cj       0.00      0.00      0.00       351\n",
      "         cpc       0.00      0.00      0.00       347\n",
      "      decsci       0.00      0.00      0.00       388\n",
      " development       0.00      0.00      0.00       366\n",
      "         fbs       0.00      0.00      0.00       347\n",
      "    finplain       0.00      0.00      0.00       329\n",
      "    generate       0.93      0.60      0.73        91\n",
      " h-elsevier3       0.00      0.00      0.00       348\n",
      "  h-physrev3       0.00      0.00      0.00       354\n",
      "  h-physrev4       0.01      0.30      0.02       363\n",
      "  h-physrev5       0.00      0.00      0.00       333\n",
      "        hum2       0.00      0.00      0.00       378\n",
      "    humanbio       0.00      0.00      0.00       401\n",
      "    humannat       0.00      0.00      0.00       399\n",
      "        iaea       0.00      0.00      0.00       384\n",
      "       jbact       0.00      0.00      0.00       383\n",
      "         jcc       0.00      0.00      0.00       367\n",
      "         jcp       0.00      0.00      0.00       354\n",
      "         jmb       0.00      0.00      0.00       374\n",
      "   jneurosci       0.00      0.00      0.00       367\n",
      "         jpc       0.00      0.00      0.00       365\n",
      "    jphysiol       0.00      0.00      0.00       367\n",
      "     jqt1999       0.00      0.00      0.00       368\n",
      "         jtb       0.00      0.00      0.00       334\n",
      "      jtbnew       0.00      0.00      0.00       349\n",
      "         mla       0.02      0.08      0.03       374\n",
      "        mlaa       0.00      0.00      0.00       347\n",
      "    namunsrt       0.00      0.00      0.00       312\n",
      "         nar       0.00      0.00      0.00       353\n",
      "      natbib       0.00      0.00      0.00       353\n",
      "      neuron       0.00      0.00      0.00       382\n",
      "   newcastle       0.01      0.16      0.01       306\n",
      "          nf       0.00      0.00      0.00       395\n",
      "       nflet       0.00      0.00      0.00       349\n",
      "        pccp       0.00      0.00      0.00       366\n",
      "  perception       0.00      0.00      0.00       359\n",
      "          pf       0.00      0.00      0.00       325\n",
      "       phjcp       0.00      0.00      0.00       377\n",
      "     plainyr       0.00      0.00      0.00       397\n",
      "        pnas       0.00      0.00      0.00       382\n",
      "    pnas2009       0.02      0.02      0.02       379\n",
      "        ppcf       0.00      0.00      0.00       350\n",
      "      report       0.00      0.00      0.00       354\n",
      " revcompchem       0.00      0.00      0.00       331\n",
      "         rmp       0.00      0.00      0.00       344\n",
      "       these       0.00      0.00      0.00       387\n",
      "   ugost2003       0.00      0.00      0.00       258\n",
      "  ugost2003s       0.00      0.00      0.00       299\n",
      "   ugost2008       0.00      0.00      0.00       269\n",
      "  ugost2008l       0.00      0.00      0.00       274\n",
      " ugost2008ls       0.00      0.00      0.00       290\n",
      "ugost2008mod       0.00      0.00      0.00       261\n",
      "  ugost2008n       0.00      0.00      0.00         1\n",
      " ugost2008ns       0.00      0.00      0.00         1\n",
      "  ugost2008s       0.00      0.00      0.00       259\n",
      "      utcaps       0.00      0.00      0.00       350\n",
      "      utphys       0.00      0.00      0.00       349\n",
      "         vak       0.00      0.00      0.00       343\n",
      "   vancouver       0.00      0.00      0.00       366\n",
      "     wmaainf       0.00      0.00      0.00       373\n",
      "     zootaxa       0.00      0.00      0.00       383\n",
      "\n",
      "    accuracy                           0.01     30639\n",
      "   macro avg       0.01      0.02      0.01     30639\n",
      "weighted avg       0.00      0.01      0.00     30639\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alrabosh/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(small_y_test, sgd_model.predict(small_X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f322750e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alrabosh/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/alrabosh/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   IEEEannot       0.00      0.00      0.00     68214\n",
      "    IEEEtran       0.02      0.42      0.04     71885\n",
      "   IEEEtranN       0.02      0.00      0.01     72192\n",
      "   IEEEtranS       0.00      0.00      0.00     71399\n",
      "  IEEEtranSA       0.00      0.00      0.00     73342\n",
      "  IEEEtranSN       0.01      0.12      0.02     73041\n",
      "      JHEP-2       0.00      0.00      0.00     69699\n",
      "  aaai-named       0.00      0.00      0.00     68715\n",
      "    abstract       0.50      0.00      0.00     68980\n",
      "    acmtrans       0.00      0.00      0.00     70132\n",
      "      aichej       0.00      0.00      0.00     67093\n",
      "         aip       0.00      0.00      0.00     70589\n",
      "    alphanum       0.00      0.00      0.00     68850\n",
      "         ama       0.00      0.00      0.00     68383\n",
      "    amsalpha       0.00      0.00      0.00     52899\n",
      "    amsplain       0.00      0.00      0.00     53169\n",
      "    annotate       0.00      0.00      0.00     69499\n",
      "  annotation       0.00      0.00      0.00     64098\n",
      "         apa       0.00      0.00      0.00     70292\n",
      "apalike-ejor       0.00      0.00      0.00     65250\n",
      "     apasoft       0.00      0.00      0.00     70439\n",
      "      astron       0.00      0.00      0.00     69915\n",
      "         bbs       0.00      0.00      0.00     70441\n",
      " besjournals       0.00      0.00      0.00     70286\n",
      "  bestpapers       0.00      0.00      0.00       933\n",
      "     biolett       0.00      0.00      0.00     67875\n",
      "      bookdb       0.00      0.00      0.00     53664\n",
      "         cbe       0.00      0.00      0.00     70469\n",
      "     chicago       0.00      0.00      0.00     70302\n",
      "    chicagoa       0.00      0.00      0.00     69984\n",
      "          cj       0.00      0.00      0.00     69357\n",
      "         cpc       0.00      0.00      0.00     70716\n",
      "      decsci       0.00      0.00      0.00     68880\n",
      " development       0.00      0.00      0.00     69376\n",
      "         fbs       0.00      0.00      0.00     70386\n",
      "    finplain       0.00      0.00      0.00     68571\n",
      "    generate       0.86      0.60      0.71     16875\n",
      " h-elsevier3       0.00      0.00      0.00     70124\n",
      "  h-physrev3       0.00      0.00      0.00     68925\n",
      "  h-physrev4       0.01      0.29      0.02     69125\n",
      "  h-physrev5       0.00      0.00      0.00     68779\n",
      "        hum2       0.00      0.00      0.00     70320\n",
      "    humanbio       0.00      0.00      0.00     70087\n",
      "    humannat       0.00      0.00      0.00     70429\n",
      "        iaea       0.00      0.00      0.00     70684\n",
      "       jbact       0.00      0.00      0.00     70188\n",
      "         jcc       0.00      0.00      0.00     70456\n",
      "         jcp       0.00      0.00      0.00     68898\n",
      "         jmb       0.00      0.00      0.00     69622\n",
      "   jneurosci       0.00      0.00      0.00     70448\n",
      "         jpc       0.00      0.00      0.00     69457\n",
      "    jphysiol       0.00      0.00      0.00     70435\n",
      "     jqt1999       0.00      0.00      0.00     69354\n",
      "         jtb       0.00      0.00      0.00     70484\n",
      "      jtbnew       0.00      0.00      0.00     68741\n",
      "         mla       0.02      0.10      0.04     69937\n",
      "        mlaa       0.00      0.00      0.00     70452\n",
      "    namunsrt       0.00      0.00      0.00     69437\n",
      "         nar       0.00      0.00      0.00     68959\n",
      "      natbib       0.00      0.00      0.00     69374\n",
      "      neuron       0.00      0.00      0.00     69691\n",
      "   newcastle       0.01      0.13      0.01     63735\n",
      "          nf       0.00      0.00      0.00     70663\n",
      "       nflet       0.00      0.00      0.00     70528\n",
      "        pccp       0.00      0.00      0.00     68697\n",
      "  perception       0.00      0.00      0.00     68886\n",
      "          pf       0.00      0.00      0.00     69297\n",
      "       phjcp       0.00      0.00      0.00     69890\n",
      "     plainyr       0.00      0.00      0.00     70586\n",
      "        pnas       0.00      0.00      0.00     70595\n",
      "    pnas2009       0.03      0.03      0.03     69002\n",
      "        ppcf       0.00      0.00      0.00     69755\n",
      "      report       0.00      0.00      0.00     69076\n",
      " revcompchem       0.00      0.00      0.00     70127\n",
      "         rmp       0.00      0.00      0.00     65000\n",
      "       these       0.00      0.00      0.00     69588\n",
      "   ugost2003       0.00      0.00      0.00     53960\n",
      "  ugost2003s       0.00      0.00      0.00     53591\n",
      "   ugost2008       0.00      0.00      0.00     53961\n",
      "  ugost2008l       0.00      0.00      0.00     53884\n",
      " ugost2008ls       0.00      0.00      0.00     53629\n",
      "ugost2008mod       0.00      0.00      0.00     53881\n",
      "  ugost2008n       0.07      0.07      0.07       282\n",
      " ugost2008ns       0.01      0.04      0.02       283\n",
      "  ugost2008s       0.00      0.00      0.00     53974\n",
      "      utcaps       0.00      0.00      0.00     68516\n",
      "      utphys       0.00      0.00      0.00     68413\n",
      "         vak       0.00      0.00      0.00     68653\n",
      "   vancouver       0.00      0.00      0.00     66071\n",
      "     wmaainf       0.00      0.00      0.00     69666\n",
      "     zootaxa       0.00      0.00      0.00     70542\n",
      "\n",
      "    accuracy                           0.01   5905327\n",
      "   macro avg       0.02      0.02      0.01   5905327\n",
      "weighted avg       0.01      0.01      0.00   5905327\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alrabosh/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(big_y, sgd_model.predict(big_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b87444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "guided-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('2grams_bib_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "simplified-florida",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df, small_df = train_test_split(df, test_size=0.017, random_state=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-count",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_X, small_y = small_df.drop(['style_name'], axis=1), small_df.style_name\n",
    "big_X, big_y = big_df.drop(['style_name'], axis=1), big_df.style_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00ab8b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df.to_csv('small_df_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8689c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small_X_train, small_X_test, small_y_train, small_y_test = train_test_split(small_X, small_y, test_size=0.3)\n",
    "small_X_train, small_X_val, small_y_train, small_y_val = train_test_split(small_X_train, small_y_train, test_size=0.25)\n",
    "train_dataset = Pool(data=small_X_train, label=small_y_train)\n",
    "test_data = Pool(data=small_X_test, label=small_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-cancer",
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_model = CatBoostClassifier(iterations=1000,\n",
    "                           learning_rate=0.05,\n",
    "                           depth=4,\n",
    "                           task_type='GPU',                                                \n",
    "                           loss_function='MultiClass',\n",
    "                           eval_metric='Accuracy')\n",
    "boost_model.fit(train_dataset, eval_set=(small_X_val, small_y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeadb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(small_y_test, boost_model.predict(small_X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30e9cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(big_y, boost_model.predict(big_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30a19f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fe517ad3910>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_model = CatBoostClassifier()\n",
    "boost_model.load_model('boost_model_50.cbm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
