{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "21lsmc6gBFw-",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /home/alrabosh/.local/lib/python3.8/site-packages (1.1.1)\n",
      "Requirement already satisfied: graphviz in /home/alrabosh/.local/lib/python3.8/site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.8/dist-packages (from catboost) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from catboost) (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from catboost) (1.19.5)\n",
      "Requirement already satisfied: plotly in /home/alrabosh/.local/lib/python3.8/site-packages (from catboost) (5.11.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from catboost) (3.3.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from catboost) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->catboost) (2021.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/alrabosh/.local/lib/python3.8/site-packages (from plotly->catboost) (8.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (8.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FgnYLa9hnPuO"
   },
   "outputs": [],
   "source": [
    "import joblib # для сериализации и сохранения обученной модели в файл\n",
    "# (см. https://machinelearningmastery.ru/save-load-machine-learning-models-python-scikit-learn/)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import catboost\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, log_loss, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, CategoricalNB\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FLmR8NBToJbh"
   },
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv('drive/MyDrive/bib_data_union_v2.csv.zip', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WLvVXkKApEVi",
    "outputId": "11677993-ad98-4236-873e-67e343ab4829"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6007277, 23)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "2kOs2bhQpJmq",
    "outputId": "71969604-d668-4d32-93df-f4e90ea7c9ec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-09c93130-e0ec-48b7-bb7f-fd40ed54183a\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>square_brackets</th>\n",
       "      <th>round_brackets</th>\n",
       "      <th>slashes</th>\n",
       "      <th>inverse_slashes</th>\n",
       "      <th>quotes</th>\n",
       "      <th>dots</th>\n",
       "      <th>commas</th>\n",
       "      <th>semicolons</th>\n",
       "      <th>colons</th>\n",
       "      <th>abstract</th>\n",
       "      <th>...</th>\n",
       "      <th>begin_ref</th>\n",
       "      <th>tirets</th>\n",
       "      <th>key</th>\n",
       "      <th>annotation</th>\n",
       "      <th>capital_letters</th>\n",
       "      <th>years</th>\n",
       "      <th>sine</th>\n",
       "      <th>et_al</th>\n",
       "      <th>etc</th>\n",
       "      <th>style_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>iaea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bestpapers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bestpapers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bestpapers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bestpapers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09c93130-e0ec-48b7-bb7f-fd40ed54183a')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-09c93130-e0ec-48b7-bb7f-fd40ed54183a button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-09c93130-e0ec-48b7-bb7f-fd40ed54183a');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   square_brackets  round_brackets  slashes  inverse_slashes  quotes  dots  \\\n",
       "0                1               1        1                0       0     5   \n",
       "1                1               1        5                0       0    11   \n",
       "2                1               2        5                0       0    18   \n",
       "3                1               2        5                0       0    18   \n",
       "4                1               2        5                0       0    17   \n",
       "\n",
       "   commas  semicolons  colons  abstract  ...  begin_ref  tirets  key  \\\n",
       "0      10           0       0         0  ...          1       0    0   \n",
       "1       3           0       2         0  ...          3       0    0   \n",
       "2       2           0       3         0  ...          3       0    0   \n",
       "3       2           0       4         0  ...          3       0    0   \n",
       "4       2           0       3         0  ...          3       0    0   \n",
       "\n",
       "   annotation  capital_letters  years  sine  et_al  etc  style_name  \n",
       "0           0         0.552632      2     0      1    0        iaea  \n",
       "1           0         0.647059      9     0      0    0  bestpapers  \n",
       "2           0         0.647059      2     0      0    0  bestpapers  \n",
       "3           0         0.454545      2     0      0    0  bestpapers  \n",
       "4           0         0.588235      3     0      0    0  bestpapers  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7EScLI_TofdC"
   },
   "outputs": [],
   "source": [
    "X = data_frame.drop(['style_name'], axis=1)\n",
    "y = data_frame.style_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DVHw4Zp9mkcE"
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, columns=['begin_ref', 'abstract', 'key', 'annotation', 'sine', 'et_al', 'etc', ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MJsUcCfYp7jB"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(classifier, test_data, test_answers, _average=None):\n",
    "    print(f\"accuracy = {classifier.score(test_data, test_answers)}\")\n",
    "    precisions = precision_score(test_answers, classifier.predict(test_data), average=_average, zero_division=0)\n",
    "    recalls = recall_score(test_answers, classifier.predict(test_data), average=_average, zero_division=0)\n",
    "    f1_scores = f1_score(test_answers, classifier.predict(test_data), average=_average, zero_division=0)\n",
    "    print(\"precision: \", \"min = \", precisions.min(), \"max = \", precisions.max(), \"mean = \", np.mean(precisions), \"median = \", np.median(precisions))\n",
    "    print(\"recall: \", \"min = \", recalls.min(), \"max = \", recalls.max(), \"mean = \", np.mean(recalls), \"median = \", np.median(recalls))\n",
    "    print(\"f1_score: \", \"min = \", f1_scores.min(), \"max = \", f1_scores.max(), \"mean = \", np.mean(f1_scores), \"median = \", np.median(f1_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZNTh2EcWf_4"
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_rgRjUelDF7N",
    "outputId": "412e7a5c-b9c9-4d8a-f0f9-bc153bbc29d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5389785393722284"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(criterion='entropy', n_estimators=40, max_depth=11, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vvNtElX-dtFW",
    "outputId": "3f952e2f-1ac4-4c14-fb57-ddea2dbcad40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   IEEEannot       0.30      0.01      0.03     13829\n",
      "    IEEEtran       0.34      0.58      0.42     14633\n",
      "   IEEEtranN       0.49      0.52      0.51     14815\n",
      "   IEEEtranS       0.35      0.12      0.18     14399\n",
      "  IEEEtranSA       0.76      0.87      0.81     14944\n",
      "  IEEEtranSN       0.48      0.33      0.39     14934\n",
      "      JHEP-2       0.28      0.01      0.03     14299\n",
      "  aaai-named       0.98      0.79      0.88     13986\n",
      "    abstract       0.76      0.94      0.84     14027\n",
      "    acmtrans       0.57      0.54      0.56     14271\n",
      "      aichej       0.65      0.68      0.66     13692\n",
      "         aip       0.28      0.01      0.02     14315\n",
      "    alphanum       0.62      0.88      0.73     13942\n",
      "         ama       0.66      0.47      0.55     13918\n",
      "    amsalpha       0.86      0.88      0.87     10774\n",
      "    amsplain       0.34      0.62      0.44     10792\n",
      "    annotate       0.79      0.80      0.79     14295\n",
      "  annotation       1.00      1.00      1.00     12997\n",
      "         apa       0.50      0.43      0.47     14180\n",
      "apalike-ejor       0.98      0.86      0.92     13228\n",
      "     apasoft       0.88      0.89      0.89     14177\n",
      "      astron       0.60      0.79      0.68     13968\n",
      "         bbs       0.82      0.70      0.76     14346\n",
      " besjournals       0.58      0.78      0.67     14155\n",
      "  bestpapers       1.00      0.03      0.06       185\n",
      "     biolett       0.70      0.64      0.67     13722\n",
      "      bookdb       0.80      0.83      0.81     10884\n",
      "         cbe       0.56      0.44      0.49     14536\n",
      "     chicago       0.36      0.52      0.43     14260\n",
      "    chicagoa       0.32      0.15      0.20     14338\n",
      "          cj       0.39      0.51      0.44     14280\n",
      "         cpc       0.33      0.16      0.21     14246\n",
      "      decsci       0.62      0.54      0.58     14064\n",
      " development       0.72      0.87      0.79     14091\n",
      "         fbs       0.34      0.83      0.48     14321\n",
      "    finplain       0.15      0.40      0.22     14119\n",
      "    generate       0.19      0.00      0.01      3453\n",
      " h-elsevier3       0.46      0.22      0.30     14435\n",
      "  h-physrev3       0.47      0.00      0.01     14027\n",
      "  h-physrev4       0.32      0.06      0.10     13830\n",
      "  h-physrev5       0.33      0.02      0.03     13847\n",
      "        hum2       0.51      0.69      0.59     14387\n",
      "    humanbio       0.46      0.46      0.46     14321\n",
      "    humannat       0.57      0.43      0.49     14422\n",
      "        iaea       0.54      0.76      0.63     14326\n",
      "       jbact       0.33      0.53      0.41     14291\n",
      "         jcc       0.63      0.57      0.60     14214\n",
      "         jcp       0.32      0.06      0.11     14016\n",
      "         jmb       0.91      0.76      0.83     14134\n",
      "   jneurosci       0.53      0.86      0.66     14394\n",
      "         jpc       0.71      0.60      0.65     14031\n",
      "    jphysiol       0.89      0.73      0.80     14259\n",
      "     jqt1999       0.99      0.71      0.83     14134\n",
      "         jtb       0.55      0.59      0.57     14208\n",
      "      jtbnew       0.70      0.49      0.58     14055\n",
      "         mla       0.46      0.34      0.39     14345\n",
      "        mlaa       0.45      0.42      0.43     14409\n",
      "    namunsrt       0.99      1.00      0.99     14083\n",
      "         nar       0.44      0.61      0.51     14067\n",
      "      natbib       0.72      0.86      0.79     14036\n",
      "      neuron       0.67      0.72      0.70     14119\n",
      "   newcastle       0.89      0.84      0.86     12972\n",
      "          nf       0.58      0.11      0.19     14102\n",
      "       nflet       0.63      0.19      0.29     14261\n",
      "        pccp       0.38      0.36      0.37     14027\n",
      "  perception       0.96      0.95      0.96     13939\n",
      "          pf       0.14      0.24      0.18     14022\n",
      "       phjcp       0.15      0.08      0.10     14217\n",
      "     plainyr       0.12      0.55      0.19     14667\n",
      "        pnas       0.42      0.79      0.55     14326\n",
      "    pnas2009       0.42      0.15      0.22     13908\n",
      "        ppcf       0.62      0.90      0.73     14303\n",
      "      report       0.19      0.25      0.22     14044\n",
      " revcompchem       0.63      0.32      0.43     14446\n",
      "         rmp       0.93      0.72      0.81     13350\n",
      "       these       0.80      0.96      0.87     14262\n",
      "   ugost2003       0.48      0.36      0.41     10994\n",
      "  ugost2003s       0.48      0.60      0.53     10764\n",
      "   ugost2008       0.20      0.43      0.27     11132\n",
      "  ugost2008l       0.25      0.25      0.25     10899\n",
      " ugost2008ls       0.19      0.05      0.08     10954\n",
      "ugost2008mod       0.98      0.38      0.54     11049\n",
      "  ugost2008n       0.31      0.15      0.21        65\n",
      " ugost2008ns       0.31      0.25      0.28        61\n",
      "  ugost2008s       0.22      0.13      0.16     11023\n",
      "      utcaps       0.52      0.55      0.54     14049\n",
      "      utphys       0.42      0.44      0.43     13764\n",
      "         vak       0.95      0.98      0.96     14008\n",
      "   vancouver       0.74      0.84      0.79     13498\n",
      "     wmaainf       0.98      0.90      0.94     14207\n",
      "     zootaxa       0.79      0.72      0.75     14338\n",
      "\n",
      "    accuracy                           0.54   1201456\n",
      "   macro avg       0.56      0.52      0.51   1201456\n",
      "weighted avg       0.56      0.54      0.52   1201456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MJBGn5UfXXQc"
   },
   "outputs": [],
   "source": [
    "precision_score(y_test, clf.predict(X_test), average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YgYhr9irOczi",
    "outputId": "687d4667-be6c-402f-e71d-3b40572b9671"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.57334071e-02, 1.40270769e-01, 8.54970224e-02, 3.52857883e-06,\n",
       "       6.35333558e-02, 4.53995573e-02, 2.30159064e-02, 3.46565340e-02,\n",
       "       5.66727065e-02, 2.92628458e-03, 1.62570014e-02, 6.35904016e-02,\n",
       "       2.84581430e-02, 3.16135388e-01, 1.95883331e-02, 9.04565353e-03,\n",
       "       2.84745424e-06, 2.29252288e-02, 6.97758733e-03, 1.41364037e-03,\n",
       "       3.78955668e-02, 1.13740366e-06])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GeWNN19xbLPe"
   },
   "outputs": [],
   "source": [
    "y_list = list(y)\n",
    "y_set = set(y_list)\n",
    "for style in y_set:\n",
    "  print(style, y_list.count(style))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iBTajIBBYPcZ"
   },
   "outputs": [],
   "source": [
    "precisions = precision_score(y_test, clf.predict(X_test), average=None)\n",
    "recalls = recall_score(y_test, clf.predict(X_test), average=None)\n",
    "f1_scores = f1_score(y_test, clf.predict(X_test), average=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YSmuzGlMdb12",
    "outputId": "79fe1932-cf4d-4349-9d97-1dfcbd9f655f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  min =  0.11790302527973477 max =  1.0 mean =  0.5440775699164183 median =  0.49117680116893336\n",
      "recall:  min =  0.007471980074719801 max =  0.9984328395935493 mean =  0.5150078729198585 median =  0.5418823529411765\n",
      "f1_score:  min =  0.014519731943410276 max =  0.9793527321617209 mean =  0.49919371625718445 median =  0.4951682969354887\n"
     ]
    }
   ],
   "source": [
    "print(\"precision: \", \"min = \", precisions.min(), \"max = \", precisions.max(), \"mean = \", np.mean(precisions), \"median = \", np.median(precisions))\n",
    "print(\"recall: \", \"min = \", recalls.min(), \"max = \", recalls.max(), \"mean = \", np.mean(recalls), \"median = \", np.median(recalls))\n",
    "print(\"f1_score: \", \"min = \", f1_scores.min(), \"max = \", f1_scores.max(), \"mean = \", np.mean(f1_scores), \"median = \", np.median(f1_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRmnX-HBcKD0"
   },
   "source": [
    "clf1 = RandomForestClassifier(criterion='gini', max_depth=8, n_estimators=50) ==> 46%\n",
    "\n",
    "clf2 = RandomForestClassifier(criterion='gini', n_estimators=20, max_depth=10, n_jobs=-1) ==> 50%\n",
    "\n",
    "clf3 = RandomForestClassifier(criterion='entropy', n_estimators=20, max_depth=10, n_jobs=-1) ==> 51.6%\n",
    "\n",
    "clf4 = RandomForestClassifier(criterion='entropy', n_estimators=30, max_depth=10, n_jobs=-1) ==> 52%\n",
    "\n",
    "clf5 = RandomForestClassifier(criterion='entropy', n_estimators=20, max_depth=11, n_jobs=-1) ==> 52.8%\n",
    "\n",
    "clf6 = RandomForestClassifier(criterion='entropy', n_estimators=30, max_depth=11, n_jobs=-1) ==> 53.6%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WonGA5W4chJa"
   },
   "source": [
    "# Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFWNaOf0qgPK"
   },
   "outputs": [],
   "source": [
    "X = X.drop(['abstract', 'annotation', 'inverse_slashes', 'etc'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0fxHpl8L9Eg"
   },
   "outputs": [],
   "source": [
    "y_list = list(y)\n",
    "for style in y_list:\n",
    "  if 'ugost2003' in style:\n",
    "    style = 'ugost2003'\n",
    "  elif 'ugost2008' in style:\n",
    "    style = 'ugost2008'\n",
    "  elif 'IEEE' in style:\n",
    "    style = 'IEEE'\n",
    "  elif 'h-physrev' in style:\n",
    "    style = 'h-physrev'\n",
    "y = pd.Series(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "gyd-mUyIAwOj"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "k-89m_iJcfsd"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'begin_ref_1' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-8c2c2c665f0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_dataset = catboost.Pool(data=X_train, label=y_train, cat_features=[ 'begin_ref_1',\n\u001b[0m\u001b[1;32m      2\u001b[0m  \u001b[0;34m'begin_ref_2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m  \u001b[0;34m'begin_ref_3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m  \u001b[0;34m'begin_ref_4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m  \u001b[0;34m'begin_ref_5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, column_description, pairs, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m    790\u001b[0m                     )\n\u001b[1;32m    791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m                 self._init(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n\u001b[0m\u001b[1;32m    793\u001b[0m                            group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\n\u001b[1;32m    794\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\u001b[0m\n\u001b[1;32m   1369\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcat_features\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m             \u001b[0mcat_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_features_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_string_feature_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cat_features'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_string_feature_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cat_features'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_get_features_indices\u001b[0;34m(features, feature_names)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"feature names should be a sequence, but got \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         return [\n\u001b[0m\u001b[1;32m    270\u001b[0m             \u001b[0mfeature_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTRING_TYPES\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         return [\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mfeature_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTRING_TYPES\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         ]\n",
      "\u001b[0;31mValueError\u001b[0m: 'begin_ref_1' is not in list"
     ]
    }
   ],
   "source": [
    "train_dataset = catboost.Pool(data=X_train, label=y_train, cat_features=[ 'begin_ref_1',\n",
    " 'begin_ref_2',\n",
    " 'begin_ref_3',\n",
    " 'begin_ref_4',\n",
    " 'begin_ref_5',\n",
    " 'begin_ref_6',\n",
    " 'begin_ref_7',\n",
    " 'begin_ref_8',\n",
    " 'begin_ref_9',\n",
    " 'begin_ref_10',\n",
    " 'begin_ref_11',\n",
    " 'begin_ref_12',\n",
    " 'abstract_0',\n",
    " 'abstract_1',\n",
    " 'key_0',\n",
    " 'key_1',\n",
    " 'annotation_0',\n",
    " 'annotation_1',\n",
    " 'sine_0',\n",
    " 'sine_1',\n",
    " 'sine_2',\n",
    " 'et_al_0',\n",
    " 'et_al_1',\n",
    " 'et_al_2',\n",
    " 'et_al_3',\n",
    " 'etc_0',\n",
    " 'etc_1'])\n",
    "test_dataset = catboost.Pool(data=X_test, label=y_test, cat_features=[ 'begin_ref_1',\n",
    " 'begin_ref_2',\n",
    " 'begin_ref_3',\n",
    " 'begin_ref_4',\n",
    " 'begin_ref_5',\n",
    " 'begin_ref_6',\n",
    " 'begin_ref_7',\n",
    " 'begin_ref_8',\n",
    " 'begin_ref_9',\n",
    " 'begin_ref_10',\n",
    " 'begin_ref_11',\n",
    " 'begin_ref_12',\n",
    " 'abstract_0',\n",
    " 'abstract_1',\n",
    " 'key_0',\n",
    " 'key_1',\n",
    " 'annotation_0',\n",
    " 'annotation_1',\n",
    " 'sine_0',\n",
    " 'sine_1',\n",
    " 'sine_2',\n",
    " 'et_al_0',\n",
    " 'et_al_1',\n",
    " 'et_al_2',\n",
    " 'et_al_3',\n",
    " 'etc_0',\n",
    " 'etc_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vju2YNZ0wZ9U",
    "outputId": "1ad22b7d-071f-43e7-bdbe-69bcae888a93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.3080077\ttest: 0.3075002\tbest: 0.3075002 (0)\ttotal: 3.6s\tremaining: 14m 57s\n",
      "1:\tlearn: 0.3493131\ttest: 0.3488401\tbest: 0.3488401 (1)\ttotal: 7.2s\tremaining: 14m 52s\n",
      "2:\tlearn: 0.3974112\ttest: 0.3965921\tbest: 0.3965921 (2)\ttotal: 10.9s\tremaining: 14m 58s\n",
      "3:\tlearn: 0.4142674\ttest: 0.4132910\tbest: 0.4132910 (3)\ttotal: 14.5s\tremaining: 14m 52s\n",
      "4:\tlearn: 0.4298913\ttest: 0.4288663\tbest: 0.4288663 (4)\ttotal: 18.1s\tremaining: 14m 46s\n",
      "5:\tlearn: 0.4329104\ttest: 0.4317653\tbest: 0.4317653 (5)\ttotal: 21.6s\tremaining: 14m 40s\n",
      "6:\tlearn: 0.4393770\ttest: 0.4383831\tbest: 0.4383831 (6)\ttotal: 25.2s\tremaining: 14m 34s\n",
      "7:\tlearn: 0.4436465\ttest: 0.4426504\tbest: 0.4426504 (7)\ttotal: 28.7s\tremaining: 14m 28s\n",
      "8:\tlearn: 0.4436998\ttest: 0.4426962\tbest: 0.4426962 (8)\ttotal: 32.3s\tremaining: 14m 25s\n",
      "9:\tlearn: 0.4533373\ttest: 0.4521023\tbest: 0.4521023 (9)\ttotal: 35.9s\tremaining: 14m 22s\n",
      "10:\tlearn: 0.4557785\ttest: 0.4544628\tbest: 0.4544628 (10)\ttotal: 39.6s\tremaining: 14m 19s\n",
      "11:\tlearn: 0.4588930\ttest: 0.4575590\tbest: 0.4575590 (11)\ttotal: 43.2s\tremaining: 14m 17s\n",
      "12:\tlearn: 0.4598533\ttest: 0.4585886\tbest: 0.4585886 (12)\ttotal: 46.9s\tremaining: 14m 15s\n",
      "13:\tlearn: 0.4660363\ttest: 0.4646479\tbest: 0.4646479 (13)\ttotal: 50.5s\tremaining: 14m 11s\n",
      "14:\tlearn: 0.4665482\ttest: 0.4651298\tbest: 0.4651298 (14)\ttotal: 54s\tremaining: 14m 5s\n",
      "15:\tlearn: 0.4691456\ttest: 0.4677733\tbest: 0.4677733 (15)\ttotal: 57.7s\tremaining: 14m 3s\n",
      "16:\tlearn: 0.4719419\ttest: 0.4704783\tbest: 0.4704783 (16)\ttotal: 1m 1s\tremaining: 14m 1s\n",
      "17:\tlearn: 0.4729552\ttest: 0.4714854\tbest: 0.4714854 (17)\ttotal: 1m 4s\tremaining: 13m 56s\n",
      "18:\tlearn: 0.4758272\ttest: 0.4743844\tbest: 0.4743844 (18)\ttotal: 1m 8s\tremaining: 13m 53s\n",
      "19:\tlearn: 0.4785603\ttest: 0.4769763\tbest: 0.4769763 (19)\ttotal: 1m 12s\tremaining: 13m 48s\n",
      "20:\tlearn: 0.4817098\ttest: 0.4801699\tbest: 0.4801699 (20)\ttotal: 1m 15s\tremaining: 13m 46s\n",
      "21:\tlearn: 0.4830729\ttest: 0.4815516\tbest: 0.4815516 (21)\ttotal: 1m 19s\tremaining: 13m 40s\n",
      "22:\tlearn: 0.4879819\ttest: 0.4862775\tbest: 0.4862775 (22)\ttotal: 1m 22s\tremaining: 13m 38s\n",
      "23:\tlearn: 0.4967233\ttest: 0.4950061\tbest: 0.4950061 (23)\ttotal: 1m 26s\tremaining: 13m 34s\n",
      "24:\tlearn: 0.5009923\ttest: 0.4992218\tbest: 0.4992218 (24)\ttotal: 1m 30s\tremaining: 13m 32s\n",
      "25:\tlearn: 0.5041196\ttest: 0.5023014\tbest: 0.5023014 (25)\ttotal: 1m 33s\tremaining: 13m 27s\n",
      "26:\tlearn: 0.5065583\ttest: 0.5048175\tbest: 0.5048175 (26)\ttotal: 1m 37s\tremaining: 13m 24s\n",
      "27:\tlearn: 0.5099228\ttest: 0.5081618\tbest: 0.5081618 (27)\ttotal: 1m 40s\tremaining: 13m 19s\n",
      "28:\tlearn: 0.5107166\ttest: 0.5089891\tbest: 0.5089891 (28)\ttotal: 1m 44s\tremaining: 13m 15s\n",
      "29:\tlearn: 0.5113186\ttest: 0.5096583\tbest: 0.5096583 (29)\ttotal: 1m 47s\tremaining: 13m 10s\n",
      "30:\tlearn: 0.5133986\ttest: 0.5117649\tbest: 0.5117649 (30)\ttotal: 1m 51s\tremaining: 13m 7s\n",
      "31:\tlearn: 0.5186883\ttest: 0.5170094\tbest: 0.5170094 (31)\ttotal: 1m 55s\tremaining: 13m 4s\n",
      "32:\tlearn: 0.5195686\ttest: 0.5178167\tbest: 0.5178167 (32)\ttotal: 1m 58s\tremaining: 13m\n",
      "33:\tlearn: 0.5238681\ttest: 0.5218385\tbest: 0.5218385 (33)\ttotal: 2m 2s\tremaining: 12m 58s\n",
      "34:\tlearn: 0.5252753\ttest: 0.5232759\tbest: 0.5232759 (34)\ttotal: 2m 6s\tremaining: 12m 54s\n",
      "35:\tlearn: 0.5275817\ttest: 0.5253467\tbest: 0.5253467 (35)\ttotal: 2m 9s\tremaining: 12m 50s\n",
      "36:\tlearn: 0.5281521\ttest: 0.5258178\tbest: 0.5258178 (36)\ttotal: 2m 13s\tremaining: 12m 46s\n",
      "37:\tlearn: 0.5283852\ttest: 0.5260933\tbest: 0.5260933 (37)\ttotal: 2m 16s\tremaining: 12m 40s\n",
      "38:\tlearn: 0.5301441\ttest: 0.5277763\tbest: 0.5277763 (38)\ttotal: 2m 20s\tremaining: 12m 38s\n",
      "39:\tlearn: 0.5305556\ttest: 0.5281225\tbest: 0.5281225 (39)\ttotal: 2m 23s\tremaining: 12m 34s\n",
      "40:\tlearn: 0.5335597\ttest: 0.5311381\tbest: 0.5311381 (40)\ttotal: 2m 27s\tremaining: 12m 31s\n",
      "41:\tlearn: 0.5353573\ttest: 0.5328551\tbest: 0.5328551 (41)\ttotal: 2m 31s\tremaining: 12m 30s\n",
      "42:\tlearn: 0.5359990\ttest: 0.5334677\tbest: 0.5334677 (42)\ttotal: 2m 35s\tremaining: 12m 28s\n",
      "43:\tlearn: 0.5374600\ttest: 0.5348685\tbest: 0.5348685 (43)\ttotal: 2m 39s\tremaining: 12m 24s\n",
      "44:\tlearn: 0.5376315\ttest: 0.5350092\tbest: 0.5350092 (44)\ttotal: 2m 42s\tremaining: 12m 20s\n",
      "45:\tlearn: 0.5404705\ttest: 0.5377001\tbest: 0.5377001 (45)\ttotal: 2m 46s\tremaining: 12m 17s\n",
      "46:\tlearn: 0.5414821\ttest: 0.5385516\tbest: 0.5385516 (46)\ttotal: 2m 49s\tremaining: 12m 14s\n",
      "47:\tlearn: 0.5437402\ttest: 0.5406931\tbest: 0.5406931 (47)\ttotal: 2m 53s\tremaining: 12m 11s\n",
      "48:\tlearn: 0.5449160\ttest: 0.5419433\tbest: 0.5419433 (48)\ttotal: 2m 57s\tremaining: 12m 8s\n",
      "49:\tlearn: 0.5457019\ttest: 0.5426982\tbest: 0.5426982 (49)\ttotal: 3m 1s\tremaining: 12m 5s\n",
      "50:\tlearn: 0.5473369\ttest: 0.5442397\tbest: 0.5442397 (50)\ttotal: 3m 5s\tremaining: 12m 1s\n",
      "51:\tlearn: 0.5483030\ttest: 0.5452293\tbest: 0.5452293 (51)\ttotal: 3m 8s\tremaining: 11m 57s\n",
      "52:\tlearn: 0.5499729\ttest: 0.5467658\tbest: 0.5467658 (52)\ttotal: 3m 12s\tremaining: 11m 54s\n",
      "53:\tlearn: 0.5507031\ttest: 0.5474699\tbest: 0.5474699 (53)\ttotal: 3m 15s\tremaining: 11m 50s\n",
      "54:\tlearn: 0.5509331\ttest: 0.5476264\tbest: 0.5476264 (54)\ttotal: 3m 19s\tremaining: 11m 46s\n",
      "55:\tlearn: 0.5523009\ttest: 0.5490130\tbest: 0.5490130 (55)\ttotal: 3m 23s\tremaining: 11m 43s\n",
      "56:\tlearn: 0.5532977\ttest: 0.5498895\tbest: 0.5498895 (56)\ttotal: 3m 26s\tremaining: 11m 39s\n",
      "57:\tlearn: 0.5546725\ttest: 0.5511912\tbest: 0.5511912 (57)\ttotal: 3m 30s\tremaining: 11m 35s\n",
      "58:\tlearn: 0.5560871\ttest: 0.5525404\tbest: 0.5525404 (58)\ttotal: 3m 33s\tremaining: 11m 32s\n",
      "59:\tlearn: 0.5567594\ttest: 0.5531896\tbest: 0.5531896 (59)\ttotal: 3m 37s\tremaining: 11m 28s\n",
      "60:\tlearn: 0.5575620\ttest: 0.5538979\tbest: 0.5538979 (60)\ttotal: 3m 41s\tremaining: 11m 25s\n",
      "61:\tlearn: 0.5592469\ttest: 0.5555268\tbest: 0.5555268 (61)\ttotal: 3m 45s\tremaining: 11m 22s\n",
      "62:\tlearn: 0.5601353\ttest: 0.5564940\tbest: 0.5564940 (62)\ttotal: 3m 48s\tremaining: 11m 18s\n",
      "63:\tlearn: 0.5611535\ttest: 0.5573088\tbest: 0.5573088 (63)\ttotal: 3m 52s\tremaining: 11m 15s\n",
      "64:\tlearn: 0.5624281\ttest: 0.5585306\tbest: 0.5585306 (64)\ttotal: 3m 56s\tremaining: 11m 12s\n",
      "65:\tlearn: 0.5633003\ttest: 0.5594495\tbest: 0.5594495 (65)\ttotal: 3m 59s\tremaining: 11m 9s\n",
      "66:\tlearn: 0.5643238\ttest: 0.5605216\tbest: 0.5605216 (66)\ttotal: 4m 3s\tremaining: 11m 5s\n",
      "67:\tlearn: 0.5650837\ttest: 0.5611292\tbest: 0.5611292 (67)\ttotal: 4m 7s\tremaining: 11m 2s\n",
      "68:\tlearn: 0.5660520\ttest: 0.5620880\tbest: 0.5620880 (68)\ttotal: 4m 11s\tremaining: 10m 58s\n",
      "69:\tlearn: 0.5665952\ttest: 0.5627389\tbest: 0.5627389 (69)\ttotal: 4m 14s\tremaining: 10m 54s\n",
      "70:\tlearn: 0.5676034\ttest: 0.5636661\tbest: 0.5636661 (70)\ttotal: 4m 18s\tremaining: 10m 50s\n",
      "71:\tlearn: 0.5695611\ttest: 0.5654256\tbest: 0.5654256 (71)\ttotal: 4m 21s\tremaining: 10m 47s\n",
      "72:\tlearn: 0.5697520\ttest: 0.5655172\tbest: 0.5655172 (72)\ttotal: 4m 25s\tremaining: 10m 44s\n",
      "73:\tlearn: 0.5705737\ttest: 0.5663229\tbest: 0.5663229 (73)\ttotal: 4m 29s\tremaining: 10m 40s\n",
      "74:\tlearn: 0.5712296\ttest: 0.5668963\tbest: 0.5668963 (74)\ttotal: 4m 33s\tremaining: 10m 37s\n",
      "75:\tlearn: 0.5723047\ttest: 0.5678710\tbest: 0.5678710 (75)\ttotal: 4m 37s\tremaining: 10m 34s\n",
      "76:\tlearn: 0.5727863\ttest: 0.5682738\tbest: 0.5682738 (76)\ttotal: 4m 40s\tremaining: 10m 31s\n",
      "77:\tlearn: 0.5733862\ttest: 0.5688465\tbest: 0.5688465 (77)\ttotal: 4m 44s\tremaining: 10m 27s\n",
      "78:\tlearn: 0.5734766\ttest: 0.5689721\tbest: 0.5689721 (78)\ttotal: 4m 47s\tremaining: 10m 23s\n",
      "79:\tlearn: 0.5741169\ttest: 0.5693991\tbest: 0.5693991 (79)\ttotal: 4m 51s\tremaining: 10m 19s\n",
      "80:\tlearn: 0.5745395\ttest: 0.5697196\tbest: 0.5697196 (80)\ttotal: 4m 55s\tremaining: 10m 16s\n",
      "81:\tlearn: 0.5751249\ttest: 0.5701940\tbest: 0.5701940 (81)\ttotal: 4m 59s\tremaining: 10m 13s\n",
      "82:\tlearn: 0.5756662\ttest: 0.5707641\tbest: 0.5707641 (82)\ttotal: 5m 2s\tremaining: 10m 9s\n",
      "83:\tlearn: 0.5762668\ttest: 0.5713551\tbest: 0.5713551 (83)\ttotal: 5m 6s\tremaining: 10m 5s\n",
      "84:\tlearn: 0.5769077\ttest: 0.5719560\tbest: 0.5719560 (84)\ttotal: 5m 10s\tremaining: 10m 2s\n",
      "85:\tlearn: 0.5773494\ttest: 0.5723580\tbest: 0.5723580 (85)\ttotal: 5m 13s\tremaining: 9m 58s\n",
      "86:\tlearn: 0.5779437\ttest: 0.5729939\tbest: 0.5729939 (86)\ttotal: 5m 17s\tremaining: 9m 54s\n",
      "87:\tlearn: 0.5787275\ttest: 0.5737871\tbest: 0.5737871 (87)\ttotal: 5m 20s\tremaining: 9m 50s\n",
      "88:\tlearn: 0.5791009\ttest: 0.5741509\tbest: 0.5741509 (88)\ttotal: 5m 24s\tremaining: 9m 47s\n",
      "89:\tlearn: 0.5795343\ttest: 0.5745520\tbest: 0.5745520 (89)\ttotal: 5m 28s\tremaining: 9m 43s\n",
      "90:\tlearn: 0.5799940\ttest: 0.5750298\tbest: 0.5750298 (90)\ttotal: 5m 31s\tremaining: 9m 39s\n",
      "91:\tlearn: 0.5807916\ttest: 0.5757464\tbest: 0.5757464 (91)\ttotal: 5m 35s\tremaining: 9m 35s\n",
      "92:\tlearn: 0.5815182\ttest: 0.5763540\tbest: 0.5763540 (92)\ttotal: 5m 39s\tremaining: 9m 32s\n",
      "93:\tlearn: 0.5819075\ttest: 0.5767760\tbest: 0.5767760 (93)\ttotal: 5m 42s\tremaining: 9m 28s\n",
      "94:\tlearn: 0.5822196\ttest: 0.5770532\tbest: 0.5770532 (94)\ttotal: 5m 46s\tremaining: 9m 24s\n",
      "95:\tlearn: 0.5824812\ttest: 0.5772979\tbest: 0.5772979 (95)\ttotal: 5m 49s\tremaining: 9m 21s\n",
      "96:\tlearn: 0.5830309\ttest: 0.5778131\tbest: 0.5778131 (96)\ttotal: 5m 53s\tremaining: 9m 18s\n",
      "97:\tlearn: 0.5835069\ttest: 0.5783524\tbest: 0.5783524 (97)\ttotal: 5m 57s\tremaining: 9m 14s\n",
      "98:\tlearn: 0.5838318\ttest: 0.5786346\tbest: 0.5786346 (98)\ttotal: 6m 1s\tremaining: 9m 11s\n",
      "99:\tlearn: 0.5840413\ttest: 0.5788510\tbest: 0.5788510 (99)\ttotal: 6m 4s\tremaining: 9m 7s\n",
      "100:\tlearn: 0.5843068\ttest: 0.5791057\tbest: 0.5791057 (100)\ttotal: 6m 8s\tremaining: 9m 3s\n",
      "101:\tlearn: 0.5850881\ttest: 0.5797283\tbest: 0.5797283 (101)\ttotal: 6m 12s\tremaining: 9m\n",
      "102:\tlearn: 0.5854135\ttest: 0.5799971\tbest: 0.5799971 (102)\ttotal: 6m 15s\tremaining: 8m 56s\n",
      "103:\tlearn: 0.5859229\ttest: 0.5805847\tbest: 0.5805847 (103)\ttotal: 6m 19s\tremaining: 8m 52s\n",
      "104:\tlearn: 0.5863760\ttest: 0.5809551\tbest: 0.5809551 (104)\ttotal: 6m 22s\tremaining: 8m 48s\n",
      "105:\tlearn: 0.5866684\ttest: 0.5812331\tbest: 0.5812331 (105)\ttotal: 6m 26s\tremaining: 8m 45s\n",
      "106:\tlearn: 0.5871761\ttest: 0.5816318\tbest: 0.5816318 (106)\ttotal: 6m 30s\tremaining: 8m 41s\n",
      "107:\tlearn: 0.5878589\ttest: 0.5821328\tbest: 0.5821328 (107)\ttotal: 6m 34s\tremaining: 8m 38s\n",
      "108:\tlearn: 0.5880417\ttest: 0.5822460\tbest: 0.5822460 (108)\ttotal: 6m 37s\tremaining: 8m 34s\n",
      "109:\tlearn: 0.5886551\ttest: 0.5827929\tbest: 0.5827929 (109)\ttotal: 6m 41s\tremaining: 8m 31s\n",
      "110:\tlearn: 0.5888896\ttest: 0.5830001\tbest: 0.5830001 (110)\ttotal: 6m 45s\tremaining: 8m 27s\n",
      "111:\tlearn: 0.5893399\ttest: 0.5834088\tbest: 0.5834088 (111)\ttotal: 6m 48s\tremaining: 8m 23s\n",
      "112:\tlearn: 0.5895946\ttest: 0.5836910\tbest: 0.5836910 (112)\ttotal: 6m 52s\tremaining: 8m 20s\n",
      "113:\tlearn: 0.5899860\ttest: 0.5840231\tbest: 0.5840231 (113)\ttotal: 6m 56s\tremaining: 8m 16s\n",
      "114:\tlearn: 0.5905279\ttest: 0.5844991\tbest: 0.5844991 (114)\ttotal: 7m\tremaining: 8m 13s\n",
      "115:\tlearn: 0.5908267\ttest: 0.5847821\tbest: 0.5847821 (115)\ttotal: 7m 4s\tremaining: 8m 9s\n",
      "116:\tlearn: 0.5911252\ttest: 0.5850793\tbest: 0.5850793 (116)\ttotal: 7m 8s\tremaining: 8m 6s\n",
      "117:\tlearn: 0.5914803\ttest: 0.5854829\tbest: 0.5854829 (117)\ttotal: 7m 12s\tremaining: 8m 3s\n",
      "118:\tlearn: 0.5917347\ttest: 0.5858492\tbest: 0.5858492 (118)\ttotal: 7m 15s\tremaining: 7m 59s\n",
      "119:\tlearn: 0.5920496\ttest: 0.5859424\tbest: 0.5859424 (119)\ttotal: 7m 19s\tremaining: 7m 56s\n",
      "120:\tlearn: 0.5924922\ttest: 0.5862803\tbest: 0.5862803 (120)\ttotal: 7m 23s\tremaining: 7m 52s\n",
      "121:\tlearn: 0.5927180\ttest: 0.5864584\tbest: 0.5864584 (121)\ttotal: 7m 27s\tremaining: 7m 49s\n",
      "122:\tlearn: 0.5931281\ttest: 0.5869037\tbest: 0.5869037 (122)\ttotal: 7m 30s\tremaining: 7m 45s\n",
      "123:\tlearn: 0.5935886\ttest: 0.5872982\tbest: 0.5872982 (123)\ttotal: 7m 34s\tremaining: 7m 41s\n",
      "124:\tlearn: 0.5939185\ttest: 0.5875579\tbest: 0.5875579 (124)\ttotal: 7m 38s\tremaining: 7m 38s\n",
      "125:\tlearn: 0.5941884\ttest: 0.5877810\tbest: 0.5877810 (125)\ttotal: 7m 41s\tremaining: 7m 34s\n",
      "126:\tlearn: 0.5943610\ttest: 0.5879325\tbest: 0.5879325 (126)\ttotal: 7m 45s\tremaining: 7m 30s\n",
      "127:\tlearn: 0.5947749\ttest: 0.5882696\tbest: 0.5882696 (127)\ttotal: 7m 49s\tremaining: 7m 27s\n",
      "128:\tlearn: 0.5950271\ttest: 0.5884660\tbest: 0.5884660 (128)\ttotal: 7m 52s\tremaining: 7m 23s\n",
      "129:\tlearn: 0.5951789\ttest: 0.5886724\tbest: 0.5886724 (129)\ttotal: 7m 56s\tremaining: 7m 19s\n",
      "130:\tlearn: 0.5954089\ttest: 0.5888281\tbest: 0.5888281 (130)\ttotal: 7m 59s\tremaining: 7m 16s\n",
      "131:\tlearn: 0.5958206\ttest: 0.5891801\tbest: 0.5891801 (131)\ttotal: 8m 3s\tremaining: 7m 12s\n",
      "132:\tlearn: 0.5963899\ttest: 0.5897503\tbest: 0.5897503 (132)\ttotal: 8m 7s\tremaining: 7m 9s\n",
      "133:\tlearn: 0.5965631\ttest: 0.5899459\tbest: 0.5899459 (133)\ttotal: 8m 11s\tremaining: 7m 5s\n",
      "134:\tlearn: 0.5969287\ttest: 0.5902355\tbest: 0.5902355 (134)\ttotal: 8m 15s\tremaining: 7m 1s\n",
      "135:\tlearn: 0.5971804\ttest: 0.5904128\tbest: 0.5904128 (135)\ttotal: 8m 18s\tremaining: 6m 58s\n",
      "136:\tlearn: 0.5976226\ttest: 0.5907657\tbest: 0.5907657 (136)\ttotal: 8m 22s\tremaining: 6m 54s\n",
      "137:\tlearn: 0.5981253\ttest: 0.5911502\tbest: 0.5911502 (137)\ttotal: 8m 26s\tremaining: 6m 51s\n",
      "138:\tlearn: 0.5983420\ttest: 0.5913575\tbest: 0.5913575 (138)\ttotal: 8m 30s\tremaining: 6m 47s\n",
      "139:\tlearn: 0.5985715\ttest: 0.5915614\tbest: 0.5915614 (139)\ttotal: 8m 33s\tremaining: 6m 43s\n",
      "140:\tlearn: 0.5986883\ttest: 0.5917245\tbest: 0.5917245 (140)\ttotal: 8m 37s\tremaining: 6m 39s\n",
      "141:\tlearn: 0.5990783\ttest: 0.5919826\tbest: 0.5919826 (141)\ttotal: 8m 40s\tremaining: 6m 36s\n",
      "142:\tlearn: 0.5994265\ttest: 0.5923147\tbest: 0.5923147 (142)\ttotal: 8m 44s\tremaining: 6m 32s\n",
      "143:\tlearn: 0.5997190\ttest: 0.5926318\tbest: 0.5926318 (143)\ttotal: 8m 48s\tremaining: 6m 28s\n",
      "144:\tlearn: 0.5998616\ttest: 0.5927766\tbest: 0.5927766 (144)\ttotal: 8m 51s\tremaining: 6m 25s\n",
      "145:\tlearn: 0.6000660\ttest: 0.5929031\tbest: 0.5929031 (145)\ttotal: 8m 55s\tremaining: 6m 21s\n",
      "146:\tlearn: 0.6001878\ttest: 0.5930205\tbest: 0.5930205 (146)\ttotal: 8m 59s\tremaining: 6m 17s\n",
      "147:\tlearn: 0.6004594\ttest: 0.5932510\tbest: 0.5932510 (147)\ttotal: 9m 2s\tremaining: 6m 13s\n",
      "148:\tlearn: 0.6007463\ttest: 0.5934932\tbest: 0.5934932 (148)\ttotal: 9m 6s\tremaining: 6m 10s\n",
      "149:\tlearn: 0.6011963\ttest: 0.5939310\tbest: 0.5939310 (149)\ttotal: 9m 9s\tremaining: 6m 6s\n",
      "150:\tlearn: 0.6016128\ttest: 0.5942690\tbest: 0.5942690 (150)\ttotal: 9m 13s\tremaining: 6m 3s\n",
      "151:\tlearn: 0.6017262\ttest: 0.5943655\tbest: 0.5943655 (151)\ttotal: 9m 17s\tremaining: 5m 59s\n",
      "152:\tlearn: 0.6018386\ttest: 0.5944321\tbest: 0.5944321 (152)\ttotal: 9m 20s\tremaining: 5m 55s\n",
      "153:\tlearn: 0.6023544\ttest: 0.5948799\tbest: 0.5948799 (153)\ttotal: 9m 24s\tremaining: 5m 51s\n",
      "154:\tlearn: 0.6025039\ttest: 0.5949723\tbest: 0.5949723 (154)\ttotal: 9m 28s\tremaining: 5m 48s\n",
      "155:\tlearn: 0.6027783\ttest: 0.5952295\tbest: 0.5952295 (155)\ttotal: 9m 31s\tremaining: 5m 44s\n",
      "156:\tlearn: 0.6031606\ttest: 0.5954933\tbest: 0.5954933 (156)\ttotal: 9m 35s\tremaining: 5m 41s\n",
      "157:\tlearn: 0.6036547\ttest: 0.5957746\tbest: 0.5957746 (157)\ttotal: 9m 39s\tremaining: 5m 37s\n",
      "158:\tlearn: 0.6041483\ttest: 0.5961342\tbest: 0.5961342 (158)\ttotal: 9m 43s\tremaining: 5m 34s\n",
      "159:\tlearn: 0.6044798\ttest: 0.5963972\tbest: 0.5963972 (159)\ttotal: 9m 47s\tremaining: 5m 30s\n",
      "160:\tlearn: 0.6045628\ttest: 0.5964580\tbest: 0.5964580 (160)\ttotal: 9m 51s\tremaining: 5m 26s\n",
      "161:\tlearn: 0.6047590\ttest: 0.5966910\tbest: 0.5966910 (161)\ttotal: 9m 54s\tremaining: 5m 22s\n",
      "162:\tlearn: 0.6049088\ttest: 0.5968175\tbest: 0.5968175 (162)\ttotal: 9m 58s\tremaining: 5m 19s\n",
      "163:\tlearn: 0.6051543\ttest: 0.5969773\tbest: 0.5969773 (163)\ttotal: 10m 2s\tremaining: 5m 15s\n",
      "164:\tlearn: 0.6055957\ttest: 0.5974051\tbest: 0.5974051 (164)\ttotal: 10m 5s\tremaining: 5m 12s\n",
      "165:\tlearn: 0.6059353\ttest: 0.5977323\tbest: 0.5977323 (165)\ttotal: 10m 9s\tremaining: 5m 8s\n",
      "166:\tlearn: 0.6063387\ttest: 0.5980727\tbest: 0.5980727 (166)\ttotal: 10m 13s\tremaining: 5m 4s\n",
      "167:\tlearn: 0.6066259\ttest: 0.5982824\tbest: 0.5982824 (167)\ttotal: 10m 16s\tremaining: 5m 1s\n",
      "168:\tlearn: 0.6068656\ttest: 0.5984647\tbest: 0.5984647 (168)\ttotal: 10m 20s\tremaining: 4m 57s\n",
      "169:\tlearn: 0.6069494\ttest: 0.5986029\tbest: 0.5986029 (169)\ttotal: 10m 24s\tremaining: 4m 53s\n",
      "170:\tlearn: 0.6073816\ttest: 0.5988309\tbest: 0.5988309 (170)\ttotal: 10m 28s\tremaining: 4m 50s\n",
      "171:\tlearn: 0.6074779\ttest: 0.5988742\tbest: 0.5988742 (171)\ttotal: 10m 31s\tremaining: 4m 46s\n",
      "172:\tlearn: 0.6079010\ttest: 0.5992621\tbest: 0.5992621 (172)\ttotal: 10m 35s\tremaining: 4m 42s\n",
      "173:\tlearn: 0.6080339\ttest: 0.5993578\tbest: 0.5993578 (173)\ttotal: 10m 38s\tremaining: 4m 39s\n",
      "174:\tlearn: 0.6083402\ttest: 0.5995867\tbest: 0.5995867 (174)\ttotal: 10m 42s\tremaining: 4m 35s\n",
      "175:\tlearn: 0.6085646\ttest: 0.5997956\tbest: 0.5997956 (175)\ttotal: 10m 46s\tremaining: 4m 31s\n",
      "176:\tlearn: 0.6086789\ttest: 0.5999313\tbest: 0.5999313 (176)\ttotal: 10m 49s\tremaining: 4m 28s\n",
      "177:\tlearn: 0.6088090\ttest: 0.6001119\tbest: 0.6001119 (177)\ttotal: 10m 53s\tremaining: 4m 24s\n",
      "178:\tlearn: 0.6089344\ttest: 0.6002833\tbest: 0.6002833 (178)\ttotal: 10m 56s\tremaining: 4m 20s\n",
      "179:\tlearn: 0.6090252\ttest: 0.6003491\tbest: 0.6003491 (179)\ttotal: 11m\tremaining: 4m 16s\n",
      "180:\tlearn: 0.6092529\ttest: 0.6005455\tbest: 0.6005455 (180)\ttotal: 11m 4s\tremaining: 4m 13s\n",
      "181:\tlearn: 0.6094377\ttest: 0.6007544\tbest: 0.6007544 (181)\ttotal: 11m 8s\tremaining: 4m 9s\n",
      "182:\tlearn: 0.6095257\ttest: 0.6007910\tbest: 0.6007910 (182)\ttotal: 11m 11s\tremaining: 4m 5s\n",
      "183:\tlearn: 0.6099074\ttest: 0.6010457\tbest: 0.6010457 (183)\ttotal: 11m 15s\tremaining: 4m 2s\n",
      "184:\tlearn: 0.6102803\ttest: 0.6013795\tbest: 0.6013795 (184)\ttotal: 11m 19s\tremaining: 3m 58s\n",
      "185:\tlearn: 0.6104257\ttest: 0.6014161\tbest: 0.6014161 (185)\ttotal: 11m 23s\tremaining: 3m 55s\n",
      "186:\tlearn: 0.6106923\ttest: 0.6015301\tbest: 0.6015301 (186)\ttotal: 11m 26s\tremaining: 3m 51s\n",
      "187:\tlearn: 0.6109176\ttest: 0.6016983\tbest: 0.6016983 (187)\ttotal: 11m 30s\tremaining: 3m 47s\n",
      "188:\tlearn: 0.6111137\ttest: 0.6018606\tbest: 0.6018606 (188)\ttotal: 11m 34s\tremaining: 3m 44s\n",
      "189:\tlearn: 0.6112533\ttest: 0.6019729\tbest: 0.6019729 (189)\ttotal: 11m 38s\tremaining: 3m 40s\n",
      "190:\tlearn: 0.6114372\ttest: 0.6020537\tbest: 0.6020537 (190)\ttotal: 11m 42s\tremaining: 3m 36s\n",
      "191:\tlearn: 0.6115932\ttest: 0.6021527\tbest: 0.6021527 (191)\ttotal: 11m 46s\tremaining: 3m 33s\n",
      "192:\tlearn: 0.6118659\ttest: 0.6023999\tbest: 0.6023999 (192)\ttotal: 11m 50s\tremaining: 3m 29s\n",
      "193:\tlearn: 0.6120917\ttest: 0.6025988\tbest: 0.6025988 (193)\ttotal: 11m 53s\tremaining: 3m 26s\n",
      "194:\tlearn: 0.6123778\ttest: 0.6027254\tbest: 0.6027254 (194)\ttotal: 11m 57s\tremaining: 3m 22s\n",
      "195:\tlearn: 0.6125309\ttest: 0.6028202\tbest: 0.6028202 (195)\ttotal: 12m 1s\tremaining: 3m 18s\n",
      "196:\tlearn: 0.6127143\ttest: 0.6030217\tbest: 0.6030217 (196)\ttotal: 12m 4s\tremaining: 3m 14s\n",
      "197:\tlearn: 0.6129776\ttest: 0.6031698\tbest: 0.6031698 (197)\ttotal: 12m 8s\tremaining: 3m 11s\n",
      "198:\tlearn: 0.6131144\ttest: 0.6032780\tbest: 0.6032780 (198)\ttotal: 12m 12s\tremaining: 3m 7s\n",
      "199:\tlearn: 0.6133374\ttest: 0.6034628\tbest: 0.6034628 (199)\ttotal: 12m 16s\tremaining: 3m 4s\n",
      "200:\tlearn: 0.6134176\ttest: 0.6035369\tbest: 0.6035369 (200)\ttotal: 12m 19s\tremaining: 3m\n",
      "201:\tlearn: 0.6135577\ttest: 0.6036126\tbest: 0.6036126 (201)\ttotal: 12m 23s\tremaining: 2m 56s\n",
      "202:\tlearn: 0.6137503\ttest: 0.6037458\tbest: 0.6037458 (202)\ttotal: 12m 27s\tremaining: 2m 52s\n",
      "203:\tlearn: 0.6139883\ttest: 0.6038582\tbest: 0.6038582 (203)\ttotal: 12m 30s\tremaining: 2m 49s\n",
      "204:\tlearn: 0.6142302\ttest: 0.6041345\tbest: 0.6041345 (204)\ttotal: 12m 34s\tremaining: 2m 45s\n",
      "205:\tlearn: 0.6143154\ttest: 0.6041436\tbest: 0.6041436 (205)\ttotal: 12m 37s\tremaining: 2m 41s\n",
      "206:\tlearn: 0.6143118\ttest: 0.6041411\tbest: 0.6041436 (205)\ttotal: 12m 41s\tremaining: 2m 38s\n",
      "207:\tlearn: 0.6144622\ttest: 0.6043001\tbest: 0.6043001 (207)\ttotal: 12m 44s\tremaining: 2m 34s\n",
      "208:\tlearn: 0.6144619\ttest: 0.6043317\tbest: 0.6043317 (208)\ttotal: 12m 47s\tremaining: 2m 30s\n",
      "209:\tlearn: 0.6146356\ttest: 0.6044258\tbest: 0.6044258 (209)\ttotal: 12m 51s\tremaining: 2m 26s\n",
      "210:\tlearn: 0.6147646\ttest: 0.6045864\tbest: 0.6045864 (210)\ttotal: 12m 55s\tremaining: 2m 23s\n",
      "211:\tlearn: 0.6147296\ttest: 0.6045640\tbest: 0.6045864 (210)\ttotal: 12m 58s\tremaining: 2m 19s\n",
      "212:\tlearn: 0.6148059\ttest: 0.6046097\tbest: 0.6046097 (212)\ttotal: 13m 2s\tremaining: 2m 15s\n",
      "213:\tlearn: 0.6150079\ttest: 0.6048062\tbest: 0.6048062 (213)\ttotal: 13m 5s\tremaining: 2m 12s\n",
      "214:\tlearn: 0.6151142\ttest: 0.6048644\tbest: 0.6048644 (214)\ttotal: 13m 9s\tremaining: 2m 8s\n",
      "215:\tlearn: 0.6152168\ttest: 0.6049685\tbest: 0.6049685 (215)\ttotal: 13m 12s\tremaining: 2m 4s\n",
      "216:\tlearn: 0.6152873\ttest: 0.6050259\tbest: 0.6050259 (216)\ttotal: 13m 16s\tremaining: 2m 1s\n",
      "217:\tlearn: 0.6152876\ttest: 0.6050434\tbest: 0.6050434 (217)\ttotal: 13m 19s\tremaining: 1m 57s\n",
      "218:\tlearn: 0.6154474\ttest: 0.6051974\tbest: 0.6051974 (218)\ttotal: 13m 22s\tremaining: 1m 53s\n",
      "219:\tlearn: 0.6154474\ttest: 0.6051982\tbest: 0.6051982 (219)\ttotal: 13m 25s\tremaining: 1m 49s\n",
      "220:\tlearn: 0.6154463\ttest: 0.6051974\tbest: 0.6051982 (219)\ttotal: 13m 28s\tremaining: 1m 46s\n",
      "221:\tlearn: 0.6158702\ttest: 0.6054629\tbest: 0.6054629 (221)\ttotal: 13m 32s\tremaining: 1m 42s\n",
      "222:\tlearn: 0.6158683\ttest: 0.6054645\tbest: 0.6054645 (222)\ttotal: 13m 35s\tremaining: 1m 38s\n",
      "223:\tlearn: 0.6158699\ttest: 0.6054645\tbest: 0.6054645 (222)\ttotal: 13m 38s\tremaining: 1m 35s\n",
      "224:\tlearn: 0.6160000\ttest: 0.6055578\tbest: 0.6055578 (224)\ttotal: 13m 42s\tremaining: 1m 31s\n",
      "225:\tlearn: 0.6162281\ttest: 0.6057534\tbest: 0.6057534 (225)\ttotal: 13m 46s\tremaining: 1m 27s\n",
      "226:\tlearn: 0.6162278\ttest: 0.6057550\tbest: 0.6057550 (226)\ttotal: 13m 49s\tremaining: 1m 24s\n",
      "227:\tlearn: 0.6162289\ttest: 0.6057542\tbest: 0.6057550 (226)\ttotal: 13m 52s\tremaining: 1m 20s\n",
      "228:\tlearn: 0.6162425\ttest: 0.6057758\tbest: 0.6057758 (228)\ttotal: 13m 55s\tremaining: 1m 16s\n",
      "229:\tlearn: 0.6162436\ttest: 0.6057767\tbest: 0.6057767 (229)\ttotal: 13m 58s\tremaining: 1m 12s\n",
      "230:\tlearn: 0.6164453\ttest: 0.6059140\tbest: 0.6059140 (230)\ttotal: 14m 2s\tremaining: 1m 9s\n",
      "231:\tlearn: 0.6164495\ttest: 0.6059157\tbest: 0.6059157 (231)\ttotal: 14m 5s\tremaining: 1m 5s\n",
      "232:\tlearn: 0.6164481\ttest: 0.6059173\tbest: 0.6059173 (232)\ttotal: 14m 8s\tremaining: 1m 1s\n",
      "233:\tlearn: 0.6165100\ttest: 0.6059673\tbest: 0.6059673 (233)\ttotal: 14m 12s\tremaining: 58.3s\n",
      "234:\tlearn: 0.6165100\ttest: 0.6059664\tbest: 0.6059673 (233)\ttotal: 14m 15s\tremaining: 54.6s\n",
      "235:\tlearn: 0.6165732\ttest: 0.6060239\tbest: 0.6060239 (235)\ttotal: 14m 18s\tremaining: 50.9s\n",
      "236:\tlearn: 0.6165710\ttest: 0.6060180\tbest: 0.6060239 (235)\ttotal: 14m 21s\tremaining: 47.3s\n",
      "237:\tlearn: 0.6165755\ttest: 0.6060255\tbest: 0.6060255 (237)\ttotal: 14m 25s\tremaining: 43.6s\n",
      "238:\tlearn: 0.6168052\ttest: 0.6062819\tbest: 0.6062819 (238)\ttotal: 14m 28s\tremaining: 40s\n",
      "239:\tlearn: 0.6168038\ttest: 0.6062827\tbest: 0.6062827 (239)\ttotal: 14m 31s\tremaining: 36.3s\n",
      "240:\tlearn: 0.6169095\ttest: 0.6063892\tbest: 0.6063892 (240)\ttotal: 14m 35s\tremaining: 32.7s\n",
      "241:\tlearn: 0.6169098\ttest: 0.6063901\tbest: 0.6063901 (241)\ttotal: 14m 38s\tremaining: 29s\n",
      "242:\tlearn: 0.6169131\ttest: 0.6063826\tbest: 0.6063901 (241)\ttotal: 14m 41s\tremaining: 25.4s\n",
      "243:\tlearn: 0.6169117\ttest: 0.6063801\tbest: 0.6063901 (241)\ttotal: 14m 44s\tremaining: 21.8s\n",
      "244:\tlearn: 0.6169750\ttest: 0.6063959\tbest: 0.6063959 (244)\ttotal: 14m 48s\tremaining: 18.1s\n",
      "245:\tlearn: 0.6169753\ttest: 0.6063976\tbest: 0.6063976 (245)\ttotal: 14m 51s\tremaining: 14.5s\n",
      "246:\tlearn: 0.6170613\ttest: 0.6065016\tbest: 0.6065016 (246)\ttotal: 14m 54s\tremaining: 10.9s\n",
      "247:\tlearn: 0.6170618\ttest: 0.6065024\tbest: 0.6065024 (247)\ttotal: 14m 58s\tremaining: 7.24s\n",
      "248:\tlearn: 0.6170624\ttest: 0.6065058\tbest: 0.6065058 (248)\ttotal: 15m 1s\tremaining: 3.62s\n",
      "249:\tlearn: 0.6170618\ttest: 0.6065058\tbest: 0.6065058 (248)\ttotal: 15m 4s\tremaining: 0us\n",
      "bestTest = 0.606505773\n",
      "bestIteration = 248\n",
      "Shrink model to first 249 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fa82c3649a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_model = catboost.CatBoostClassifier(iterations=250,\n",
    "                           learning_rate=0.05,\n",
    "                           depth=11,\n",
    "                           loss_function='MultiClass',\n",
    "                           task_type='GPU',\n",
    "                           gpu_ram_part=0.95,\n",
    "\n",
    "                           eval_metric='Accuracy',\n",
    "                           cat_features=[ 'begin_ref_1',\n",
    " 'begin_ref_2',\n",
    " 'begin_ref_3',\n",
    " 'begin_ref_4',\n",
    " 'begin_ref_5',\n",
    " 'begin_ref_6',\n",
    " 'begin_ref_7',\n",
    " 'begin_ref_8',\n",
    " 'begin_ref_9',\n",
    " 'begin_ref_10',\n",
    " 'begin_ref_11',\n",
    " 'begin_ref_12',\n",
    " 'abstract_0',\n",
    " 'abstract_1',\n",
    " 'key_0',\n",
    " 'key_1',\n",
    " 'annotation_0',\n",
    " 'annotation_1',\n",
    " 'sine_0',\n",
    " 'sine_1',\n",
    " 'sine_2',\n",
    " 'et_al_0',\n",
    " 'et_al_1',\n",
    " 'et_al_2',\n",
    " 'et_al_3',\n",
    " 'etc_0',\n",
    " 'etc_1'])\n",
    "boost_model.fit(train_dataset,eval_set=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DX2H1hLYEHdz",
    "outputId": "6c729d59-3e0a-4e7f-d4af-6e9bd302ce73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   IEEEannot       0.31      0.07      0.12     13829\n",
      "    IEEEtran       0.33      0.49      0.39     14633\n",
      "   IEEEtranN       0.48      0.55      0.51     14815\n",
      "   IEEEtranS       0.31      0.19      0.24     14399\n",
      "  IEEEtranSA       0.80      0.90      0.85     14944\n",
      "  IEEEtranSN       0.46      0.32      0.38     14934\n",
      "      JHEP-2       0.40      0.40      0.40     14299\n",
      "  aaai-named       0.94      0.88      0.91     13986\n",
      "    abstract       0.80      0.88      0.84     14027\n",
      "    acmtrans       0.65      0.71      0.68     14271\n",
      "      aichej       0.77      0.76      0.77     13692\n",
      "         aip       0.29      0.26      0.27     14315\n",
      "    alphanum       0.88      0.84      0.86     13942\n",
      "         ama       0.60      0.66      0.63     13918\n",
      "    amsalpha       0.96      0.93      0.94     10774\n",
      "    amsplain       0.70      0.83      0.76     10792\n",
      "    annotate       0.79      0.88      0.83     14295\n",
      "  annotation       1.00      1.00      1.00     12997\n",
      "         apa       0.56      0.63      0.60     14180\n",
      "apalike-ejor       0.96      0.90      0.93     13228\n",
      "     apasoft       0.94      0.93      0.94     14177\n",
      "      astron       0.75      0.91      0.82     13968\n",
      "         bbs       0.78      0.78      0.78     14346\n",
      " besjournals       0.72      0.79      0.76     14155\n",
      "  bestpapers       0.86      0.34      0.49       185\n",
      "     biolett       0.68      0.78      0.73     13722\n",
      "      bookdb       0.86      0.86      0.86     10884\n",
      "         cbe       0.62      0.61      0.61     14536\n",
      "     chicago       0.36      0.42      0.39     14260\n",
      "    chicagoa       0.38      0.32      0.35     14338\n",
      "          cj       0.48      0.53      0.50     14280\n",
      "         cpc       0.34      0.37      0.35     14246\n",
      "      decsci       0.65      0.66      0.65     14064\n",
      " development       0.76      0.90      0.82     14091\n",
      "         fbs       0.68      0.87      0.76     14321\n",
      "    finplain       0.33      0.45      0.38     14119\n",
      "    generate       0.45      0.24      0.31      3453\n",
      " h-elsevier3       0.52      0.37      0.43     14435\n",
      "  h-physrev3       0.29      0.11      0.16     14027\n",
      "  h-physrev4       0.24      0.21      0.23     13830\n",
      "  h-physrev5       0.21      0.08      0.12     13847\n",
      "        hum2       0.79      0.80      0.79     14387\n",
      "    humanbio       0.58      0.55      0.57     14321\n",
      "    humannat       0.68      0.52      0.59     14422\n",
      "        iaea       0.50      0.76      0.61     14326\n",
      "       jbact       0.50      0.75      0.60     14291\n",
      "         jcc       0.68      0.61      0.65     14214\n",
      "         jcp       0.33      0.11      0.16     14016\n",
      "         jmb       0.87      0.83      0.85     14134\n",
      "   jneurosci       0.80      0.83      0.81     14394\n",
      "         jpc       0.70      0.68      0.69     14031\n",
      "    jphysiol       0.68      0.84      0.75     14259\n",
      "     jqt1999       0.84      0.80      0.82     14134\n",
      "         jtb       0.77      0.77      0.77     14208\n",
      "      jtbnew       0.72      0.56      0.63     14055\n",
      "         mla       0.44      0.34      0.38     14345\n",
      "        mlaa       0.44      0.46      0.45     14409\n",
      "    namunsrt       0.99      1.00      0.99     14083\n",
      "         nar       0.60      0.66      0.63     14067\n",
      "      natbib       0.85      0.89      0.87     14036\n",
      "      neuron       0.74      0.77      0.75     14119\n",
      "   newcastle       0.90      0.89      0.90     12972\n",
      "          nf       0.43      0.27      0.33     14102\n",
      "       nflet       0.44      0.27      0.33     14261\n",
      "        pccp       0.59      0.59      0.59     14027\n",
      "  perception       0.98      0.98      0.98     13939\n",
      "          pf       0.31      0.17      0.22     14022\n",
      "       phjcp       0.29      0.08      0.12     14217\n",
      "     plainyr       0.22      0.51      0.31     14667\n",
      "        pnas       0.47      0.57      0.51     14326\n",
      "    pnas2009       0.45      0.39      0.42     13908\n",
      "        ppcf       0.71      0.80      0.75     14303\n",
      "      report       0.20      0.32      0.24     14044\n",
      " revcompchem       0.52      0.70      0.60     14446\n",
      "         rmp       0.96      0.81      0.88     13350\n",
      "       these       0.96      0.96      0.96     14262\n",
      "   ugost2003       0.47      0.40      0.43     10994\n",
      "  ugost2003s       0.47      0.55      0.51     10764\n",
      "   ugost2008       0.19      0.18      0.18     11132\n",
      "  ugost2008l       0.24      0.31      0.27     10899\n",
      " ugost2008ls       0.19      0.14      0.16     10954\n",
      "ugost2008mod       0.55      0.48      0.51     11049\n",
      "  ugost2008n       0.31      0.22      0.25        65\n",
      " ugost2008ns       0.28      0.25      0.26        61\n",
      "  ugost2008s       0.20      0.15      0.17     11023\n",
      "      utcaps       0.56      0.53      0.54     14049\n",
      "      utphys       0.50      0.53      0.52     13764\n",
      "         vak       0.65      1.00      0.79     14008\n",
      "   vancouver       0.82      0.84      0.83     13498\n",
      "     wmaainf       0.98      0.94      0.96     14207\n",
      "     zootaxa       0.81      0.83      0.82     14338\n",
      "\n",
      "    accuracy                           0.61   1201456\n",
      "   macro avg       0.59      0.59      0.58   1201456\n",
      "weighted avg       0.60      0.61      0.60   1201456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, boost_model.predict(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1R9yOQCfwZ9V",
    "outputId": "6858623c-3ccc-4d94-adb4-87b1c7af75d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learn': {'Accuracy': 0.6170623674350406, 'MultiClass': 1.0738434509268624},\n",
       " 'validation': {'Accuracy': 0.6065057729954322,\n",
       "  'MultiClass': 1.082117239416175}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_model.get_best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "An4Mj6_jsjiP",
    "outputId": "a89bec5b-38db-474d-ed7f-a27120fa3c06",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-c48cd9cb-155d-4146-9340-de4ccd066df2\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Id</th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>begin_ref_1</td>\n",
       "      <td>21.717033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ampersands</td>\n",
       "      <td>15.680614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>round_brackets</td>\n",
       "      <td>15.167533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>begin_ref_3</td>\n",
       "      <td>13.150782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>begin_ref_5</td>\n",
       "      <td>6.249451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dots</td>\n",
       "      <td>4.739864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>begin_ref_11</td>\n",
       "      <td>3.814263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>slashes</td>\n",
       "      <td>2.868023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>colons</td>\n",
       "      <td>2.307490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>page_ref</td>\n",
       "      <td>2.163333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>commas</td>\n",
       "      <td>2.147454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>quotes</td>\n",
       "      <td>1.894138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>capital_letters</td>\n",
       "      <td>1.798586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ands</td>\n",
       "      <td>1.313437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>et_al_1</td>\n",
       "      <td>0.936240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>semicolons</td>\n",
       "      <td>0.638012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>et_al_0</td>\n",
       "      <td>0.568039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>begin_ref_7</td>\n",
       "      <td>0.517335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>years</td>\n",
       "      <td>0.415436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>begin_ref_8</td>\n",
       "      <td>0.412528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>key_0</td>\n",
       "      <td>0.270928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>begin_ref_2</td>\n",
       "      <td>0.254684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>begin_ref_4</td>\n",
       "      <td>0.238117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>square_brackets</td>\n",
       "      <td>0.195622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tirets</td>\n",
       "      <td>0.188894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>begin_ref_6</td>\n",
       "      <td>0.160843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>begin_ref_10</td>\n",
       "      <td>0.111425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>begin_ref_9</td>\n",
       "      <td>0.069638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>begin_ref_12</td>\n",
       "      <td>0.006662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>et_al_2</td>\n",
       "      <td>0.003596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>inverse_slashes</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>abstract_0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>abstract_1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>key_1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>annotation_0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>annotation_1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>sine_0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>sine_1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>sine_2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>et_al_3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>etc_0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>etc_1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c48cd9cb-155d-4146-9340-de4ccd066df2')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-c48cd9cb-155d-4146-9340-de4ccd066df2 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-c48cd9cb-155d-4146-9340-de4ccd066df2');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "         Feature Id  Importances\n",
       "0       begin_ref_1    21.717033\n",
       "1        ampersands    15.680614\n",
       "2    round_brackets    15.167533\n",
       "3       begin_ref_3    13.150782\n",
       "4       begin_ref_5     6.249451\n",
       "5              dots     4.739864\n",
       "6      begin_ref_11     3.814263\n",
       "7           slashes     2.868023\n",
       "8            colons     2.307490\n",
       "9          page_ref     2.163333\n",
       "10           commas     2.147454\n",
       "11           quotes     1.894138\n",
       "12  capital_letters     1.798586\n",
       "13             ands     1.313437\n",
       "14          et_al_1     0.936240\n",
       "15       semicolons     0.638012\n",
       "16          et_al_0     0.568039\n",
       "17      begin_ref_7     0.517335\n",
       "18            years     0.415436\n",
       "19      begin_ref_8     0.412528\n",
       "20            key_0     0.270928\n",
       "21      begin_ref_2     0.254684\n",
       "22      begin_ref_4     0.238117\n",
       "23  square_brackets     0.195622\n",
       "24           tirets     0.188894\n",
       "25      begin_ref_6     0.160843\n",
       "26     begin_ref_10     0.111425\n",
       "27      begin_ref_9     0.069638\n",
       "28     begin_ref_12     0.006662\n",
       "29          et_al_2     0.003596\n",
       "30  inverse_slashes     0.000000\n",
       "31       abstract_0     0.000000\n",
       "32       abstract_1     0.000000\n",
       "33            key_1     0.000000\n",
       "34     annotation_0     0.000000\n",
       "35     annotation_1     0.000000\n",
       "36           sine_0     0.000000\n",
       "37           sine_1     0.000000\n",
       "38           sine_2     0.000000\n",
       "39          et_al_3     0.000000\n",
       "40            etc_0     0.000000\n",
       "41            etc_1     0.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_model.get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X-7qnVppjsEN"
   },
   "outputs": [],
   "source": [
    "metrics = boost_model.eval_metrics(\n",
    "    data=train_dataset,\n",
    "    metrics=['Precision','Recall','F1','Accuracy'],\n",
    "    ntree_start=0,\n",
    "    ntree_end=0,\n",
    "    eval_period=1,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ch-hQJ7VEB_V"
   },
   "outputs": [],
   "source": [
    "from catboost import cv\n",
    "\n",
    "params = {\n",
    "    'loss_function': 'MultiClass',\n",
    "    'iterations': 250,\n",
    "    'depth': 10,\n",
    "    'random_seed': 0,\n",
    "    'learning_rate': 0.05,\n",
    "    'task_type': 'GPU',\n",
    "    'gpu_ram_part': 0.95,\n",
    "    'eval_metric': 'Accuracy'\n",
    "}\n",
    "\n",
    "cv_data = cv(\n",
    "    params=params,\n",
    "    pool=catboost.Pool(data=X, label=y),\n",
    "    fold_count=5,\n",
    "    shuffle=True,\n",
    "    partition_random_seed=0,\n",
    "    plot=True,\n",
    "    stratified=True, \n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eV63aUhvv5zF"
   },
   "outputs": [],
   "source": [
    "cv_model = catboost.CatBoostClassifier(\n",
    "                           loss_function='MultiClass',\n",
    "                           task_type='GPU',\n",
    "                           gpu_ram_part=0.95,\n",
    "                           eval_metric='Accuracy',\n",
    "                          )\n",
    "\n",
    "parameters = {\n",
    "    'iterations': range(150, 351, 50),\n",
    "    'depth': range(6, 14),\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "cv_model.grid_search(parameters, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKFlVxAYWVav"
   },
   "source": [
    "# Наивная байесовская классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jwmh1TY6YnxC"
   },
   "outputs": [],
   "source": [
    "precisions = precision_score(y_test, bayes_clf.predict(X_test), average=None)\n",
    "recalls = recall_score(y_test, bayes_clf.predict(X_test), average=None)\n",
    "f1_scores = f1_score(y_test, bayes_clf.predict(X_test), average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZXb97UaqYpEB",
    "outputId": "5aa1e741-5b4b-43ba-aed5-ace6eb748ee6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  min =  0.09152843601895734 max =  0.9041331535636246 mean =  0.3503485530217752 median =  0.34906358513121194\n",
      "recall:  min =  0.00959335624284078 max =  0.9831151104595319 mean =  0.32680261035539704 median =  0.3074704491725768\n",
      "f1_score:  min =  0.018126888217522657 max =  0.9419714216517318 mean =  0.31132752247121714 median =  0.2896955711369486\n"
     ]
    }
   ],
   "source": [
    "print(\"precision: \", \"min = \", precisions.min(), \"max = \", precisions.max(), \"mean = \", np.mean(precisions), \"median = \", np.median(precisions))\n",
    "print(\"recall: \", \"min = \", recalls.min(), \"max = \", recalls.max(), \"mean = \", np.mean(recalls), \"median = \", np.median(recalls))\n",
    "print(\"f1_score: \", \"min = \", f1_scores.min(), \"max = \", f1_scores.max(), \"mean = \", np.mean(f1_scores), \"median = \", np.median(f1_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CK8Yl6bobmCi"
   },
   "outputs": [],
   "source": [
    "cv_bayes_clf = MultinomialNB()\n",
    "parameters = {'var_smoothing': [1e-2, 5e-2, 1e-3, 5e-3, 1e-4, 5e-4, 1e-5, 5e-5, 1e-6, 5e-6, 1e-7, 5e-7]}\n",
    "grid = GridSearchCV(cv_bayes_clf, parameters)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-BF3i-FQiMFg",
    "outputId": "24d874f0-6836-4b05-d825-f2ee5e4f26e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3669924935522677"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf = grid.best_estimator_\n",
    "best_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvdT1AIu3ZOT"
   },
   "source": [
    "# Линейная классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fyU0dwPP3XuK"
   },
   "outputs": [],
   "source": [
    "sgd_clf_1 = SGDClassifier(loss='hinge', early_stopping=True, n_jobs=-1, random_state=0)\n",
    "sgd_clf_1.fit(X_train, y_train)\n",
    "sgd_clf_1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "03akx5tiDij2"
   },
   "outputs": [],
   "source": [
    "precisions = precision_score(y_test, sgd_clf_1.predict(X_test), average=None)\n",
    "recalls = recall_score(y_test, sgd_clf_1.predict(X_test), average=None)\n",
    "f1_scores = f1_score(y_test, sgd_clf_1.predict(X_test), average=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2zAwyq5PQxYV",
    "outputId": "30b73f73-67a4-4068-8921-897feeaadd5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  min =  0.0 max =  0.9944520765085069 mean =  0.40912341157097065 median =  0.38881491344873503\n",
      "recall:  min =  0.0 max =  0.9994787223959815 mean =  0.39585435843587163 median =  0.3600458190148912\n",
      "f1_score:  min =  0.0 max =  0.9946708168270137 mean =  0.36837470035717856 median =  0.3093249349582364\n"
     ]
    }
   ],
   "source": [
    "print(\"precision: \", \"min = \", precisions.min(), \"max = \", precisions.max(), \"mean = \", np.mean(precisions), \"median = \", np.median(precisions))\n",
    "print(\"recall: \", \"min = \", recalls.min(), \"max = \", recalls.max(), \"mean = \", np.mean(recalls), \"median = \", np.median(recalls))\n",
    "print(\"f1_score: \", \"min = \", f1_scores.min(), \"max = \", f1_scores.max(), \"mean = \", np.mean(f1_scores), \"median = \", np.median(f1_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vKVcGJxfEHP"
   },
   "source": [
    "# Векторизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "c1gM9DlOfKp2"
   },
   "outputs": [],
   "source": [
    "text_data_frame = pd.read_csv('./bib_data_union_v3.csv.zip', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ASdzdbVhf1k",
    "outputId": "7ec661d3-cf30-4269-f83e-c3f53d884159"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6006215, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "T5yg-GxmhxjP",
    "outputId": "32acb44f-d4c6-42b6-c2ba-58ec3205caf9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenized_record</th>\n",
       "      <th>style_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ num ] sp upword , sp caplet . sp caplet . sp...</td>\n",
       "      <td>iaea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ capword sp othword sp capword ( year ) ] sp ...</td>\n",
       "      <td>bestpapers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ capword ( year ) ] sp caplet . sp caplet . s...</td>\n",
       "      <td>bestpapers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ capword sp othword sp capword ( year ) ] sp ...</td>\n",
       "      <td>bestpapers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ capword ( year ) ] sp capword sp caplet . sp...</td>\n",
       "      <td>bestpapers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    tokenized_record  style_name\n",
       "0  [ num ] sp upword , sp caplet . sp caplet . sp...        iaea\n",
       "1  [ capword sp othword sp capword ( year ) ] sp ...  bestpapers\n",
       "2  [ capword ( year ) ] sp caplet . sp caplet . s...  bestpapers\n",
       "3  [ capword sp othword sp capword ( year ) ] sp ...  bestpapers\n",
       "4  [ capword ( year ) ] sp capword sp caplet . sp...  bestpapers"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CVb7WAkyg_O0"
   },
   "outputs": [],
   "source": [
    "corpus = text_data_frame.tokenized_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alrabosh/miniconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "# ngram_range=(1, 1) => униграммы, ngram_range=(2, 2) => биграммы и т.д.\n",
    "vectorizer = CountVectorizer(tokenizer=lambda txt: txt.split(), ngram_range=(1, 2))\n",
    "vectorized_data = vectorizer.fit_transform(corpus).toarray()\n",
    "print(\"SUCCESS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# временный код\n",
    "X = pd.read_csv('2grams_bib_data.csv')\n",
    "y = X.style_name\n",
    "X = X.drop(['style_name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data=vectorized_data, columns=vectorizer.get_feature_names_out())\n",
    "y = text_data_frame.style_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "del X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная классификация на новом датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(n_jobs=-1, random_state=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf_1 = SGDClassifier(loss='hinge', early_stopping=False, n_jobs=-1, random_state=0)\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "sgd_clf_1.fit(X_train, y_train)\n",
    "\n",
    "t_finish = time.time()\n",
    "print(t_finish - t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   IEEEannot       0.31      0.04      0.07     20957\n",
      "    IEEEtran       0.25      0.73      0.37     21931\n",
      "   IEEEtranN       0.43      0.41      0.42     21967\n",
      "   IEEEtranS       0.34      0.01      0.01     21680\n",
      "  IEEEtranSA       0.73      0.80      0.77     22415\n",
      "  IEEEtranSN       0.36      0.57      0.44     22108\n",
      "      JHEP-2       0.79      0.58      0.67     21360\n",
      "  aaai-named       0.91      0.90      0.91     20922\n",
      "    abstract       0.75      0.00      0.00     21111\n",
      "    acmtrans       0.71      0.76      0.74     21473\n",
      "      aichej       0.96      0.91      0.94     20369\n",
      "         aip       0.16      0.00      0.01     21412\n",
      "    alphanum       0.35      0.88      0.50     20977\n",
      "         ama       0.96      0.90      0.93     20961\n",
      "    amsalpha       0.97      0.92      0.94     16073\n",
      "    amsplain       0.96      0.83      0.89     16271\n",
      "    annotate       0.51      0.04      0.08     21166\n",
      "  annotation       0.97      0.94      0.95     19652\n",
      "         apa       0.76      0.86      0.81     21645\n",
      "apalike-ejor       0.93      0.88      0.91     19949\n",
      "     apasoft       0.97      0.96      0.96     21763\n",
      "      astron       0.97      0.98      0.97     21605\n",
      "         bbs       0.79      0.82      0.81     21412\n",
      " besjournals       0.97      0.93      0.95     21461\n",
      "  bestpapers       0.00      0.00      0.00       300\n",
      "     biolett       0.95      0.96      0.96     20687\n",
      "      bookdb       0.99      0.89      0.94     16427\n",
      "         cbe       0.89      0.79      0.84     21583\n",
      "     chicago       0.46      0.19      0.27     21344\n",
      "    chicagoa       0.44      0.65      0.52     21509\n",
      "          cj       0.90      0.90      0.90     21088\n",
      "         cpc       0.39      0.74      0.51     21448\n",
      "      decsci       0.92      0.82      0.87     21205\n",
      " development       0.94      0.92      0.93     21407\n",
      "         fbs       1.00      0.96      0.98     21308\n",
      "    finplain       0.61      0.64      0.62     20924\n",
      "    generate       0.47      0.36      0.41      5122\n",
      " h-elsevier3       0.29      0.64      0.40     21416\n",
      "  h-physrev3       0.02      0.01      0.01     20967\n",
      "  h-physrev4       0.26      0.05      0.09     21228\n",
      "  h-physrev5       0.15      0.50      0.23     20880\n",
      "        hum2       0.82      0.82      0.82     21527\n",
      "    humanbio       0.73      0.77      0.75     21181\n",
      "    humannat       0.86      0.96      0.91     21317\n",
      "        iaea       0.50      0.51      0.50     21432\n",
      "       jbact       0.96      0.86      0.91     21569\n",
      "         jcc       0.60      0.63      0.61     21342\n",
      "         jcp       0.30      0.16      0.21     20980\n",
      "         jmb       0.89      0.84      0.86     21214\n",
      "   jneurosci       0.91      0.95      0.93     21520\n",
      "         jpc       0.66      0.73      0.69     21432\n",
      "    jphysiol       0.91      0.90      0.90     21382\n",
      "     jqt1999       0.88      0.64      0.74     21399\n",
      "         jtb       1.00      0.97      0.99     21603\n",
      "      jtbnew       0.95      0.73      0.83     20839\n",
      "         mla       0.09      0.06      0.07     21279\n",
      "        mlaa       0.47      0.60      0.53     21366\n",
      "    namunsrt       0.98      1.00      0.99     21096\n",
      "         nar       0.92      0.85      0.89     21122\n",
      "      natbib       0.91      0.96      0.93     21296\n",
      "      neuron       0.92      0.87      0.89     21383\n",
      "   newcastle       0.97      0.89      0.93     19237\n",
      "          nf       0.35      0.31      0.33     21449\n",
      "       nflet       0.57      0.43      0.49     21458\n",
      "        pccp       0.78      0.78      0.78     20999\n",
      "  perception       1.00      0.96      0.98     21245\n",
      "          pf       0.19      0.41      0.26     20949\n",
      "       phjcp       0.09      0.04      0.05     21479\n",
      "     plainyr       0.01      0.00      0.00     21520\n",
      "        pnas       0.50      0.72      0.59     21517\n",
      "    pnas2009       0.51      0.26      0.35     20951\n",
      "        ppcf       0.66      0.88      0.75     21268\n",
      "      report       0.42      0.53      0.47     21057\n",
      " revcompchem       0.69      0.79      0.74     21249\n",
      "         rmp       0.91      0.94      0.92     19812\n",
      "       these       0.94      0.90      0.92     21288\n",
      "   ugost2003       0.50      0.00      0.00     16521\n",
      "  ugost2003s       0.50      0.94      0.65     16514\n",
      "   ugost2008       0.23      0.08      0.11     16539\n",
      "  ugost2008l       0.23      0.57      0.33     16307\n",
      " ugost2008ls       0.24      0.08      0.12     16257\n",
      "ugost2008mod       0.73      0.40      0.51     16531\n",
      "  ugost2008n       0.67      0.05      0.09        80\n",
      " ugost2008ns       0.44      0.31      0.36        87\n",
      "  ugost2008s       0.22      0.27      0.24     16558\n",
      "      utcaps       0.51      0.54      0.52     20887\n",
      "      utphys       0.55      0.47      0.51     20786\n",
      "         vak       0.97      0.98      0.97     20920\n",
      "   vancouver       0.99      0.94      0.96     20300\n",
      "     wmaainf       0.90      0.89      0.90     21200\n",
      "     zootaxa       0.93      0.90      0.91     21510\n",
      "\n",
      "    accuracy                           0.65   1802237\n",
      "   macro avg       0.65      0.62      0.61   1802237\n",
      "weighted avg       0.66      0.65      0.63   1802237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, sgd_clf_1.predict(X_test), zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.6365399183623635\n",
      "precision:  min =  0.0 max =  1.0 mean =  0.6484155952821647 median =  0.723570564864398\n",
      "recall:  min =  0.0 max =  0.986599586232838 mean =  0.6283646477473733 median =  0.7510262529832935\n",
      "f1_score:  min =  0.0 max =  0.9863568634755074 mean =  0.6173944345170069 median =  0.6971282255038298\n"
     ]
    }
   ],
   "source": [
    "print_metrics(sgd_clf_1, X_test, y_test, _average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./SGDClassifier_2grams.sav']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = './SGDClassifier_2grams.sav'\n",
    "joblib.dump(sgd_clf_1, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6455904523101013"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_clf = joblib.load('./SGDClassifier_2grams.sav')\n",
    "loaded_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Наивный Байесовский алгоритм на новом датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_clf = GaussianNB()\n",
    "nb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42989296080371225"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(classification_report(y_test, nb_clf.predict(X_test), zero_division=0))\n",
    "nb_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(nb_clf, 'GaussianNB_2grams.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.5512366353750142\n",
      "precision:  min =  0.10247349823321555 max =  0.9970263381478335 mean =  0.5722132801623461 median =  0.5541376455116653\n",
      "recall:  min =  0.04753208054981497 max =  0.9693084500767288 mean =  0.5548585606161551 median =  0.5698594245981761\n",
      "f1_score:  min =  0.08279961488551217 max =  0.9730892381394668 mean =  0.5415205346974971 median =  0.582771258739105\n"
     ]
    }
   ],
   "source": [
    "print_metrics(nb_clf, X_test, y_test, _average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Градиентный бустинг на новом датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = catboost.Pool(data=X_train, label=y_train)\n",
    "test_data = catboost.Pool(data=X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_boosting(_iterations: int, _learning_rate: float, _depth: int):\n",
    "    boost_model = catboost.CatBoostClassifier(iterations=_iterations,\n",
    "                           learning_rate=_learning_rate,\n",
    "                           depth=_depth,\n",
    "                           loss_function='MultiClass',\n",
    "#                            task_type='GPU',\n",
    "#                            gpu_ram_part=0.75,\n",
    "                           eval_metric='Accuracy')\n",
    "    time_start = time.time()\n",
    "    boost_model.fit(train_dataset,eval_set=(X_val, y_val))\n",
    "    time_finish = time.time()\n",
    "    print(time_finish - time_start)\n",
    "    return boost_model\n",
    "\n",
    "# boost_model_1 = gradient_boosting(250, 0.05, 6)\n",
    "# print(\"SUCCESS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_model_1.get_best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(boost_model_1, X_test, y_test, _average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Id</th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ num</td>\n",
       "      <td>15.665995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>( year</td>\n",
       "      <td>11.726335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>) .</td>\n",
       "      <td>7.452743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>. ,</td>\n",
       "      <td>5.989705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>num ]</td>\n",
       "      <td>5.017204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>— num</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>— othword</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>— smallet</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>— upword</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>— year</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>462 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature Id  Importances\n",
       "0        [ num    15.665995\n",
       "1       ( year    11.726335\n",
       "2          ) .     7.452743\n",
       "3          . ,     5.989705\n",
       "4        num ]     5.017204\n",
       "..         ...          ...\n",
       "457      — num     0.000000\n",
       "458  — othword     0.000000\n",
       "459  — smallet     0.000000\n",
       "460   — upword     0.000000\n",
       "461     — year     0.000000\n",
       "\n",
       "[462 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_model_1.get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = boost_model_1.eval_metrics(\n",
    "    data=train_dataset,\n",
    "    metrics=['Precision','Recall','F1','Accuracy'],\n",
    "    ntree_start=0,\n",
    "    ntree_end=0,\n",
    "    eval_period=1,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './CatBoostClassifier_2grams_v2.sav'\n",
    "joblib.dump(boost_model_1, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SGDClassifier' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ab06ae24ef20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloaded_catboost_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./CatBoostClassifier_2grams.sav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# print_metrics(loaded_catboost_model, X_test, y_test, _average=None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_catboost_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'catboost_2grams_feature_importances.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SGDClassifier' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "loaded_catboost_model = joblib.load('./CatBoostClassifier_2grams.sav')\n",
    "# print_metrics(loaded_catboost_model, X_test, y_test, _average=None)\n",
    "fi = loaded_catboost_model.feature_importances_\n",
    "f = open('catboost_2grams_feature_importances.txt', 'w')\n",
    "f.write(fi)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest на новом датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 8\n",
      "0.6121901870259536\n",
      "accuracy = 0.6121901870259536\n",
      "precision:  min =  0.0 max =  0.9922599488864549 mean =  0.5980777286744221 median =  0.6239096724171351\n",
      "recall:  min =  0.0 max =  0.9895473061255861 mean =  0.5889736611021662 median =  0.6566919076726576\n",
      "f1_score:  min =  0.0 max =  0.9842465505377902 mean =  0.5712248490553617 median =  0.5860415116182917\n",
      "___________________________\n",
      "20 9\n",
      "0.6254969866607407\n",
      "accuracy = 0.6254969866607407\n",
      "precision:  min =  0.0 max =  0.9902464065708418 mean =  0.6207565322099907 median =  0.624644315229494\n",
      "recall:  min =  0.0 max =  0.9809168519979913 mean =  0.6032118706864673 median =  0.6765921670286555\n",
      "f1_score:  min =  0.0 max =  0.9801117805037382 mean =  0.5878706135994055 median =  0.6192770198212775\n",
      "___________________________\n",
      "20 10\n",
      "0.6454280556408662\n",
      "accuracy = 0.6454280556408662\n",
      "precision:  min =  0.0 max =  0.9898599358039101 mean =  0.6252949321279772 median =  0.6232141723284018\n",
      "recall:  min =  0.0 max =  0.9942031059901238 mean =  0.6201769396455216 median =  0.7018633540372671\n",
      "f1_score:  min =  0.0 max =  0.9823354810685586 mean =  0.6019909394066633 median =  0.6472813095706376\n",
      "___________________________\n",
      "20 11\n",
      "0.6591817999468993\n",
      "accuracy = 0.6591817999468993\n",
      "precision:  min =  0.1888917998428085 max =  1.0 mean =  0.6510102760387438 median =  0.6906576728499156\n",
      "recall:  min =  0.0055008685581933985 max =  0.9975667358477063 mean =  0.6339937901701653 median =  0.741009730644479\n",
      "f1_score:  min =  0.010731431798926857 max =  0.9910486393212784 mean =  0.6193367398712646 median =  0.6888246628131021\n",
      "___________________________\n",
      "20 12\n",
      "0.6731111593844648\n",
      "accuracy = 0.6731111593844648\n",
      "precision:  min =  0.17777777777777778 max =  0.9936104530117023 mean =  0.6613794459726209 median =  0.7345554537121907\n",
      "recall:  min =  0.011001737116386797 max =  0.9953481714735561 mean =  0.6478533331602974 median =  0.775006888950124\n",
      "f1_score:  min =  0.02087338643229882 max =  0.9940029446619025 mean =  0.6367816575509253 median =  0.734720241138951\n",
      "___________________________\n",
      "30 8\n",
      "0.6189942329988323\n",
      "accuracy = 0.6189942329988323\n",
      "precision:  min =  0.0 max =  0.9939469993356462 mean =  0.606891209335614 median =  0.6315643619232368\n",
      "recall:  min =  0.0 max =  0.9876905460531024 mean =  0.597180056393067 median =  0.6403933965577802\n",
      "f1_score:  min =  0.0 max =  0.9805206626615692 mean =  0.577081548444821 median =  0.608611638916621\n",
      "___________________________\n",
      "30 9\n",
      "0.6459524041378587\n",
      "accuracy = 0.6459524041378587\n",
      "precision:  min =  0.0 max =  0.9903318903318903 mean =  0.6243164297732058 median =  0.6713718820861678\n",
      "recall:  min =  0.0 max =  0.9921992413941172 mean =  0.6211856879057444 median =  0.7632087184439234\n",
      "f1_score:  min =  0.0 max =  0.988264093887249 mean =  0.6005479914209069 median =  0.6677607458360977\n",
      "___________________________\n",
      "30 10\n",
      "0.656234628474121\n",
      "accuracy = 0.656234628474121\n",
      "precision:  min =  0.0 max =  0.991773609740046 mean =  0.6412477815964887 median =  0.6805763874009\n",
      "recall:  min =  0.0 max =  0.9985686681457095 mean =  0.6304394837144764 median =  0.7621617782827924\n",
      "f1_score:  min =  0.0 max =  0.98451207624824 mean =  0.6136257239052186 median =  0.6885222068764992\n",
      "___________________________\n",
      "30 11\n",
      "0.668243873653652\n",
      "accuracy = 0.668243873653652\n",
      "precision:  min =  0.175 max =  1.0 mean =  0.656561179570074 median =  0.7002788405421179\n",
      "recall:  min =  0.004053271569195136 max =  0.9972089028841337 mean =  0.6408477693620286 median =  0.7586231120477696\n",
      "f1_score:  min =  0.007936507936507936 max =  0.9935789360404635 mean =  0.6255738979087584 median =  0.7149715306464218\n",
      "___________________________\n",
      "30 12\n",
      "0.6810163372010277\n",
      "accuracy = 0.6810163372010277\n",
      "precision:  min =  0.17142857142857143 max =  0.9957144012290774 mean =  0.6730087554683193 median =  0.7318342563555081\n",
      "recall:  min =  0.003474232773595831 max =  0.998491162523351 mean =  0.6561468804137487 median =  0.7717885894294715\n",
      "f1_score:  min =  0.006810442678774121 max =  0.9964864477269467 mean =  0.6445370943832527 median =  0.7313448753954993\n",
      "___________________________\n",
      "40 8\n",
      "0.6333389097379839\n",
      "accuracy = 0.6333389097379839\n",
      "precision:  min =  0.0 max =  0.9949811794228356 mean =  0.6282342825915113 median =  0.6803656662082356\n",
      "recall:  min =  0.0 max =  0.9981392685894225 mean =  0.609756867260832 median =  0.727188414068631\n",
      "f1_score:  min =  0.0 max =  0.9816143007973205 mean =  0.5894646370266222 median =  0.6293732460243219\n",
      "___________________________\n",
      "40 9\n",
      "0.6510352553618796\n",
      "accuracy = 0.6510352553618796\n",
      "precision:  min =  0.0 max =  0.9947288612896238 mean =  0.639642785122441 median =  0.6655099286678234\n",
      "recall:  min =  0.0 max =  0.9975667358477063 mean =  0.6259203910430416 median =  0.75508356545961\n",
      "f1_score:  min =  0.0 max =  0.9922569957143371 mean =  0.6072124524698934 median =  0.6779520600905777\n",
      "___________________________\n",
      "40 10\n",
      "0.6589545822648692\n",
      "accuracy = 0.6589545822648692\n",
      "precision:  min =  0.0 max =  0.9946262823644357 mean =  0.6421096198878361 median =  0.6955187231430325\n",
      "recall:  min =  0.0 max =  0.9946194131573284 mean =  0.6324649383794025 median =  0.7376865410215091\n",
      "f1_score:  min =  0.0 max =  0.9890990470690154 mean =  0.6157831625759101 median =  0.6931260846600771\n",
      "___________________________\n",
      "40 11\n",
      "0.6725102393609274\n",
      "accuracy = 0.6725102393609274\n",
      "precision:  min =  0.15151515151515152 max =  1.0 mean =  0.6649364442295697 median =  0.7309990806006742\n",
      "recall:  min =  0.0014475969889982628 max =  0.9978530022185643 mean =  0.6458462004590358 median =  0.7575078753937697\n",
      "f1_score:  min =  0.002867794665901921 max =  0.98971972730224 mean =  0.631611028134404 median =  0.7167287553899857\n",
      "___________________________\n",
      "40 12\n",
      "0.6802681002188115\n",
      "accuracy = 0.6802681002188115\n",
      "precision:  min =  0.1487603305785124 max =  1.0 mean =  0.6685013159274936 median =  0.7467857142857143\n",
      "recall:  min =  0.0052113491603937466 max =  0.9989265011092822 mean =  0.6549770435022322 median =  0.7718912009090263\n",
      "f1_score:  min =  0.01006993006993007 max =  0.9950341849586182 mean =  0.6418074649589743 median =  0.7318607527831772\n",
      "___________________________\n",
      "50 8\n",
      "0.6373431011967631\n",
      "accuracy = 0.6373431011967631\n",
      "precision:  min =  0.0 max =  0.9935201548430531 mean =  0.6196776013955417 median =  0.6562458515863534\n",
      "recall:  min =  0.0 max =  0.9987833679238531 mean =  0.6121979612976045 median =  0.7413888123449986\n",
      "f1_score:  min =  0.0 max =  0.9787063953488373 mean =  0.5907694821122605 median =  0.6715483956863266\n",
      "___________________________\n",
      "50 9\n",
      "0.6496503094904581\n",
      "accuracy = 0.6496503094904581\n",
      "precision:  min =  0.0 max =  0.989843028624192 mean =  0.6400425807536639 median =  0.6845435557193759\n",
      "recall:  min =  0.0 max =  0.9989980677019967 mean =  0.6241589635265554 median =  0.7605993892479227\n",
      "f1_score:  min =  0.0 max =  0.9835011482070306 mean =  0.6063503686610889 median =  0.6597236265588137\n",
      "___________________________\n",
      "50 10\n",
      "0.6619849836578052\n",
      "accuracy = 0.6619849836578052\n",
      "precision:  min =  0.09090909090909091 max =  1.0 mean =  0.6579674015484624 median =  0.7096847745539532\n",
      "recall:  min =  0.00028951939779965256 max =  0.9942746725828383 mean =  0.635381328319056 median =  0.767430453366968\n",
      "f1_score:  min =  0.0005772005772005771 max =  0.9930617967429989 mean =  0.6189352334237966 median =  0.7020568192426175\n",
      "___________________________\n",
      "50 11\n",
      "0.6759326536778053\n",
      "accuracy = 0.6759326536778053\n",
      "precision:  min =  0.03333333333333333 max =  1.0 mean =  0.6697021109095074 median =  0.7496198385776114\n",
      "recall:  min =  0.00028951939779965256 max =  0.9988549345165677 mean =  0.649285730275621 median =  0.7824002256381328\n",
      "f1_score:  min =  0.000574052812858783 max =  0.9959755659360402 mean =  0.6351756387825411 median =  0.7268504093136561\n",
      "___________________________\n",
      "50 12\n",
      "0.6811536665692877\n",
      "accuracy = 0.6811536665692877\n",
      "precision:  min =  0.06493506493506493 max =  1.0 mean =  0.667462029825876 median =  0.7445112155649432\n",
      "recall:  min =  0.0014475969889982628 max =  0.9989265011092822 mean =  0.6536798879300858 median =  0.7652934692752824\n",
      "f1_score:  min =  0.0028320589068252617 max =  0.9957645369705672 mean =  0.6394675564399441 median =  0.7337916161207712\n",
      "___________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for _n_estimators in range(20, 51, 10):\n",
    "    for _max_depth in range(10, 13):\n",
    "        rf_clf = RandomForestClassifier(criterion='entropy', n_estimators=_n_estimators, max_depth=_max_depth, n_jobs=-1)\n",
    "        rf_clf.fit(X_train, y_train)\n",
    "        print(_n_estimators, _max_depth)\n",
    "        print(rf_clf.score(X_test, y_test))\n",
    "        print_metrics(rf_clf, X_test, y_test, _average=None)\n",
    "        print('___________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7158403694963537"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf_2 = RandomForestClassifier(criterion='entropy', n_estimators=40, max_depth=12, n_jobs=-1)\n",
    "rf_clf_2.fit(X_train, y_train)\n",
    "rf_clf_2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RandomForestClassifier_v2.sav']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rf_clf_2, 'RandomForestClassifier_v2.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   IEEEannot       0.64      0.27      0.38     20957\n",
      "    IEEEtran       0.54      0.44      0.48     21931\n",
      "   IEEEtranN       0.60      0.70      0.64     21967\n",
      "   IEEEtranS       0.46      0.47      0.47     21680\n",
      "  IEEEtranSA       0.79      0.86      0.82     22415\n",
      "  IEEEtranSN       0.73      0.37      0.49     22108\n",
      "      JHEP-2       0.78      0.71      0.74     21360\n",
      "  aaai-named       0.85      0.92      0.89     20922\n",
      "    abstract       0.85      0.94      0.90     21111\n",
      "    acmtrans       0.71      0.72      0.71     21473\n",
      "      aichej       0.94      0.94      0.94     20369\n",
      "         aip       0.29      0.39      0.33     21412\n",
      "    alphanum       0.45      0.71      0.55     20977\n",
      "         ama       0.47      0.96      0.63     20961\n",
      "    amsalpha       0.97      0.94      0.95     16073\n",
      "    amsplain       0.83      0.94      0.88     16271\n",
      "    annotate       0.72      0.37      0.49     21166\n",
      "  annotation       0.81      0.99      0.89     19652\n",
      "         apa       0.75      0.88      0.81     21645\n",
      "apalike-ejor       0.99      0.83      0.90     19949\n",
      "     apasoft       0.98      0.95      0.97     21763\n",
      "      astron       0.85      0.99      0.91     21605\n",
      "         bbs       0.93      0.80      0.86     21412\n",
      " besjournals       0.93      0.99      0.96     21461\n",
      "  bestpapers       1.00      0.13      0.24       300\n",
      "     biolett       0.95      0.88      0.91     20687\n",
      "      bookdb       0.97      0.93      0.95     16427\n",
      "         cbe       0.94      0.72      0.82     21583\n",
      "     chicago       0.56      0.47      0.51     21344\n",
      "    chicagoa       0.57      0.45      0.51     21509\n",
      "          cj       0.89      0.95      0.92     21088\n",
      "         cpc       0.77      0.73      0.75     21448\n",
      "      decsci       0.97      0.87      0.92     21205\n",
      " development       0.88      0.97      0.92     21407\n",
      "         fbs       0.87      0.97      0.92     21308\n",
      "    finplain       0.74      0.56      0.64     20924\n",
      "    generate       0.99      0.37      0.53      5122\n",
      " h-elsevier3       0.67      0.48      0.56     21416\n",
      "  h-physrev3       0.37      0.13      0.19     20967\n",
      "  h-physrev4       0.40      0.13      0.19     21228\n",
      "  h-physrev5       0.42      0.27      0.33     20880\n",
      "        hum2       0.76      0.90      0.82     21527\n",
      "    humanbio       0.77      0.76      0.76     21181\n",
      "    humannat       0.87      0.94      0.91     21317\n",
      "        iaea       0.50      0.80      0.61     21432\n",
      "       jbact       0.96      0.87      0.91     21569\n",
      "         jcc       0.70      0.64      0.67     21342\n",
      "         jcp       0.48      0.16      0.24     20980\n",
      "         jmb       0.90      0.82      0.86     21214\n",
      "   jneurosci       0.86      0.98      0.91     21520\n",
      "         jpc       0.80      0.80      0.80     21432\n",
      "    jphysiol       0.80      0.93      0.86     21382\n",
      "     jqt1999       0.81      0.77      0.79     21399\n",
      "         jtb       0.99      0.98      0.99     21603\n",
      "      jtbnew       0.96      0.85      0.90     20839\n",
      "         mla       0.60      0.34      0.43     21279\n",
      "        mlaa       0.53      0.69      0.60     21366\n",
      "    namunsrt       0.83      1.00      0.91     21096\n",
      "         nar       0.95      0.88      0.91     21122\n",
      "      natbib       0.80      1.00      0.89     21296\n",
      "      neuron       0.85      0.93      0.89     21383\n",
      "   newcastle       1.00      0.94      0.97     19237\n",
      "          nf       0.64      0.51      0.57     21449\n",
      "       nflet       0.65      0.50      0.56     21458\n",
      "        pccp       0.50      0.84      0.62     20999\n",
      "  perception       0.99      1.00      1.00     21245\n",
      "          pf       0.36      0.26      0.30     20949\n",
      "       phjcp       0.27      0.07      0.11     21479\n",
      "     plainyr       0.44      0.80      0.56     21520\n",
      "        pnas       0.71      0.52      0.60     21517\n",
      "    pnas2009       0.61      0.80      0.69     20951\n",
      "        ppcf       0.67      0.83      0.74     21268\n",
      "      report       0.33      0.68      0.45     21057\n",
      " revcompchem       0.56      0.83      0.67     21249\n",
      "         rmp       0.88      0.93      0.91     19812\n",
      "       these       0.88      0.94      0.91     21288\n",
      "   ugost2003       0.74      0.60      0.67     16521\n",
      "  ugost2003s       0.67      0.79      0.72     16514\n",
      "   ugost2008       0.35      0.33      0.34     16539\n",
      "  ugost2008l       0.35      0.45      0.39     16307\n",
      " ugost2008ls       0.26      0.37      0.31     16257\n",
      "ugost2008mod       0.96      0.39      0.55     16531\n",
      "  ugost2008n       0.19      0.17      0.18        80\n",
      " ugost2008ns       0.16      0.11      0.13        87\n",
      "  ugost2008s       0.37      0.30      0.33     16558\n",
      "      utcaps       0.65      0.63      0.64     20887\n",
      "      utphys       0.69      0.53      0.60     20786\n",
      "         vak       0.97      0.98      0.97     20920\n",
      "   vancouver       0.96      0.97      0.97     20300\n",
      "     wmaainf       0.91      0.89      0.90     21200\n",
      "     zootaxa       0.98      0.86      0.92     21510\n",
      "\n",
      "    accuracy                           0.72   1802237\n",
      "   macro avg       0.72      0.69      0.69   1802237\n",
      "weighted avg       0.72      0.72      0.71   1802237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, rf_clf_2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'print_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f4d3406201fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'print_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "print_metrics(rf_clf, X_test, y_test, _average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка отдельными батчами\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 6 * 10**4\n",
    "i = 0\n",
    "with pd.read_csv('2grams_bib_data.csv', chunksize=chunksize) as reader:\n",
    "    for chunk in reader:        \n",
    "        X = chunk.drop(['style_name'], axis=1)\n",
    "        y = chunk.style_name\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "        train_dataset = catboost.Pool(data=X_train, label=y_train)\n",
    "        test_data = catboost.Pool(data=X_test, label=y_test)\n",
    "        \n",
    "        if i == 0:\n",
    "            boost_model = catboost.CatBoostClassifier(iterations=50,\n",
    "                           learning_rate=0.05,\n",
    "                           depth=4,\n",
    "                           task_type='GPU',                     \n",
    "                           loss_function='MultiClass',\n",
    "                           eval_metric='Accuracy')\n",
    "            boost_model.fit(train_dataset, eval_set=(X_val, y_val))\n",
    "        else:\n",
    "            boost_model.fit(train_dataset, eval_set=(X_val, y_val), init_model='cat_boost_model.cbm')\n",
    "        print(boost_model.get_best_score())\n",
    "        boost_model.save_model('cat_boost_model.cbm')\n",
    "        i += 1\n",
    "        del X, y, X_train, X_test, y_train, y_test, X_val, y_val, train_dataset, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Градиентный бустинг (2-граммы) на GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('2grams_bib_data.csv')\n",
    "X = df.drop(['style_name'], axis=1)\n",
    "y = df.style_name\n",
    "del df\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "del X, y\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "train_dataset = catboost.Pool(data=X_train, label=y_train)\n",
    "test_data = catboost.Pool(data=X_test, label=y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_model = catboost.CatBoostClassifier(iterations=250,\n",
    "                           learning_rate=0.05,\n",
    "                           depth=4,\n",
    "                           task_type='GPU',                                                \n",
    "                           loss_function='MultiClass',\n",
    "                           eval_metric='Accuracy')\n",
    "time_start = time.time()\n",
    "boost_model.fit(train_dataset, eval_set=(X_val, y_val))\n",
    "time_finish = time.time()\n",
    "print(time_finish - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(boost_model, 'CatBoostModel_2grams_v2.sav')\n",
    "boost_model.save_model('CatBoostModel_2grams_v2.cbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   IEEEannot       0.68      0.57      0.62     13766\n",
      "    IEEEtran       0.70      0.64      0.67     14624\n",
      "   IEEEtranN       0.77      0.84      0.81     14765\n",
      "   IEEEtranS       0.63      0.68      0.65     14383\n",
      "  IEEEtranSA       0.92      0.92      0.92     14937\n",
      "  IEEEtranSN       0.85      0.73      0.78     14727\n",
      "      JHEP-2       0.82      0.83      0.83     14364\n",
      "  aaai-named       0.95      0.97      0.96     14087\n",
      "    abstract       0.99      0.96      0.98     13930\n",
      "    acmtrans       0.88      0.88      0.88     14318\n",
      "      aichej       0.98      0.97      0.98     13565\n",
      "         aip       0.59      0.59      0.59     14162\n",
      "    alphanum       0.71      0.77      0.74     14081\n",
      "         ama       0.95      0.96      0.95     13835\n",
      "    amsalpha       0.98      0.97      0.98     10881\n",
      "    amsplain       0.95      0.95      0.95     10898\n",
      "    annotate       0.75      0.69      0.72     14175\n",
      "  annotation       0.99      0.99      0.99     13011\n",
      "         apa       0.93      0.91      0.92     14310\n",
      "apalike-ejor       0.98      0.96      0.97     13300\n",
      "     apasoft       0.98      0.99      0.98     14280\n",
      "      astron       1.00      0.99      0.99     14237\n",
      "         bbs       0.92      0.92      0.92     14271\n",
      " besjournals       0.99      0.99      0.99     14182\n",
      "  bestpapers       0.96      0.56      0.71       183\n",
      "     biolett       0.94      0.98      0.96     13699\n",
      "      bookdb       0.98      0.97      0.97     10915\n",
      "         cbe       0.93      0.91      0.92     14541\n",
      "     chicago       0.77      0.72      0.74     14284\n",
      "    chicagoa       0.74      0.76      0.75     14443\n",
      "          cj       0.95      0.97      0.96     14288\n",
      "         cpc       0.83      0.82      0.82     14285\n",
      "      decsci       0.98      0.95      0.96     13990\n",
      " development       0.97      0.97      0.97     14136\n",
      "         fbs       0.99      0.98      0.99     14148\n",
      "    finplain       0.81      0.83      0.82     14052\n",
      "    generate       0.99      0.99      0.99      3454\n",
      " h-elsevier3       0.74      0.69      0.71     14393\n",
      "  h-physrev3       0.60      0.50      0.55     14015\n",
      "  h-physrev4       0.65      0.53      0.58     13824\n",
      "  h-physrev5       0.67      0.54      0.60     13778\n",
      "        hum2       0.94      0.95      0.94     14411\n",
      "    humanbio       0.84      0.89      0.86     14235\n",
      "    humannat       0.97      0.99      0.98     14372\n",
      "        iaea       0.74      0.85      0.79     14273\n",
      "       jbact       0.94      0.97      0.96     14398\n",
      "         jcc       0.84      0.86      0.85     14435\n",
      "         jcp       0.60      0.49      0.54     13896\n",
      "         jmb       0.92      0.91      0.91     14099\n",
      "   jneurosci       0.96      0.97      0.97     14392\n",
      "         jpc       0.87      0.84      0.85     14182\n",
      "    jphysiol       0.90      0.94      0.92     14345\n",
      "     jqt1999       0.90      0.86      0.88     14189\n",
      "         jtb       0.99      0.99      0.99     14197\n",
      "      jtbnew       0.97      0.96      0.96     14017\n",
      "         mla       0.77      0.77      0.77     14290\n",
      "        mlaa       0.77      0.77      0.77     14319\n",
      "    namunsrt       1.00      1.00      1.00     13973\n",
      "         nar       0.97      0.95      0.96     14274\n",
      "      natbib       0.97      0.99      0.98     13939\n",
      "      neuron       0.94      0.98      0.96     14051\n",
      "   newcastle       0.99      0.98      0.99     12978\n",
      "          nf       0.72      0.71      0.71     14232\n",
      "       nflet       0.68      0.71      0.70     14474\n",
      "        pccp       0.84      0.86      0.85     14007\n",
      "  perception       1.00      1.00      1.00     13918\n",
      "          pf       0.43      0.60      0.50     13991\n",
      "       phjcp       0.57      0.50      0.54     14125\n",
      "     plainyr       0.78      0.86      0.82     14516\n",
      "        pnas       0.75      0.84      0.79     14360\n",
      "    pnas2009       0.81      0.72      0.76     13997\n",
      "        ppcf       0.83      0.89      0.86     14498\n",
      "      report       0.52      0.71      0.60     13977\n",
      " revcompchem       0.90      0.93      0.91     14345\n",
      "         rmp       0.96      0.98      0.97     13480\n",
      "       these       0.97      0.97      0.97     14203\n",
      "   ugost2003       0.80      0.64      0.71     11092\n",
      "  ugost2003s       0.69      0.83      0.76     10762\n",
      "   ugost2008       0.52      0.49      0.50     11156\n",
      "  ugost2008l       0.47      0.58      0.52     10961\n",
      " ugost2008ls       0.54      0.52      0.53     10762\n",
      "ugost2008mod       0.79      0.61      0.69     11027\n",
      "  ugost2008n       0.29      0.28      0.28        57\n",
      " ugost2008ns       0.31      0.27      0.29        59\n",
      "  ugost2008s       0.49      0.53      0.51     10954\n",
      "      utcaps       0.79      0.74      0.76     14108\n",
      "      utphys       0.78      0.78      0.78     13795\n",
      "         vak       0.99      0.99      0.99     13982\n",
      "   vancouver       0.99      0.99      0.99     13359\n",
      "     wmaainf       0.97      0.96      0.97     14141\n",
      "     zootaxa       0.97      0.96      0.97     14371\n",
      "\n",
      "    accuracy                           0.84   1201491\n",
      "   macro avg       0.83      0.82      0.82   1201491\n",
      "weighted avg       0.84      0.84      0.84   1201491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, boost_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Замеры времени"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alrabosh/miniconda3/lib/python3.10/site-packages/sklearn/base.py:299: UserWarning: Trying to unpickle estimator SGDClassifier from version 0.24.1 when using version 1.2.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.0001,\n",
       " 'average': False,\n",
       " 'class_weight': None,\n",
       " 'early_stopping': False,\n",
       " 'epsilon': 0.1,\n",
       " 'eta0': 0.0,\n",
       " 'fit_intercept': True,\n",
       " 'l1_ratio': 0.15,\n",
       " 'learning_rate': 'optimal',\n",
       " 'loss': 'hinge',\n",
       " 'max_iter': 1000,\n",
       " 'n_iter_no_change': 5,\n",
       " 'n_jobs': -1,\n",
       " 'penalty': 'l2',\n",
       " 'power_t': 0.5,\n",
       " 'random_state': 0,\n",
       " 'shuffle': True,\n",
       " 'tol': 0.001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf = joblib.load('SGDClassifier_2grams.sav')\n",
    "sgd_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "sgd_clf = SGDClassifier(alpha=0.0001, epsilon=0.1, l1_ratio=0.15, loss='hinge', max_iter=1000, n_iter_no_change=5, n_jobs=8, random_state=0)\n",
    "start = time.time()\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "finish = time.time()\n",
    "print(finish - start)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
